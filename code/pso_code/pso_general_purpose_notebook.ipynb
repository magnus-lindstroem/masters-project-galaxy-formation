{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "from os.path import expanduser\n",
    "home_dir = expanduser(\"~\")\n",
    "module_path = home_dir + '/code/modules/'\n",
    "fig_dir = 'figures/'\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "import time\n",
    "import datetime\n",
    "import importlib\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data_processing\n",
    "%aimport plotting\n",
    "# %aimport pso\n",
    "%aimport pso_parallel_training_queue\n",
    "from data_processing import *\n",
    "from plotting import *\n",
    "# from pso import *\n",
    "from pso_parallel_training_queue import *\n",
    "\n",
    "np.random.seed(999)\n",
    "random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General parameters\n",
    "total_set_size = 2.9e5 # how many examples will be used for training+validation+testing\n",
    "train_size = 2e5\n",
    "val_size = .5e5\n",
    "test_size = .4e5\n",
    "input_features = ['Halo_mass', 'Halo_mass_peak', 'Scale_peak_mass', 'Scale_half_mass']#, 'Redshift']\n",
    "output_features = ['Stellar_mass', 'SFR']\n",
    "redshifts = [0]#,.1,.2,.5,1,2,3,4,6,8]\n",
    "same_n_points_per_redshift = False # if using the smf in the objective function, must be false!\n",
    "outputs_to_weigh = ['Stellar_mass']\n",
    "weigh_by_redshift = True\n",
    "\n",
    "reinforcement_learning = True\n",
    "real_observations = False\n",
    "\n",
    "verbatim = True\n",
    "\n",
    "### Network parameters\n",
    "nr_hidden_layers = 6\n",
    "activation_function = 'tanh'\n",
    "output_activation = {'SFR': None, 'Stellar_mass': None}\n",
    "nr_neurons_per_layer = 6\n",
    "regularisation_strength = 1e-2\n",
    "std_penalty = False\n",
    "norm = {'input': 'zero_mean_unit_std',\n",
    "        'output': 'zero_mean_unit_std'} # 'none',   'zero_mean_unit_std',   'zero_to_one'\n",
    "\n",
    "### PSO parameters\n",
    "nr_processes = 30\n",
    "nr_iterations = 1000\n",
    "x_min = -10\n",
    "x_max = 10\n",
    "alpha = 1\n",
    "delta_t = 1\n",
    "c1 = 2\n",
    "c2 = 2\n",
    "inertia_weight_start = 1.4\n",
    "inertia_weight_min = 0.1\n",
    "exploration_fraction = 0.8            # start making sure that the network did not converge to a local minimum\n",
    "min_std_tol = 0.01                # minimum allowed std for any parameter\n",
    "pso_param_dict = {\n",
    "    'nr_particles': 3 * nr_processes,\n",
    "    'patience': 1000,\n",
    "    'patience_parameter': 'train',\n",
    "    'restart_check_interval': 200\n",
    "}\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the selected galaxyfile\n",
    "galaxies, data_keys, unit_dict = load_galfiles(redshifts=redshifts, equal_numbers=same_n_points_per_redshift)\n",
    "    \n",
    "# prepare the training data\n",
    "training_data_dict = divide_train_data(galaxies, data_keys, input_features, output_features, redshifts, weigh_by_redshift, outputs_to_weigh,\n",
    "                                       int(total_set_size), train_size=int(train_size), val_size=int(val_size), test_size=int(test_size), pso=True)\n",
    "training_data_dict = normalise_data(training_data_dict, norm, pso=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:43:36  Iteration    0, particle  0, new swarm best. Train: 5.512e+02, Val: 2.222e+05\n",
      "18:43:38  Iteration    0, particle  1, new swarm best. Train: 9.629e+01, Val: 1.357e+07\n",
      "18:44:05  Iteration    1, particle  2, new swarm best. Train: 4.353e+01, Val: 5.113e+07\n",
      "18:44:32  Iteration    2, particle  2, new swarm best. Train: 4.027e+01, Val: 4.079e+01\n",
      "18:44:35  Iteration    2, particle 63, new swarm best. Train: 3.835e+01, Val: 1.966e+05\n",
      "18:44:37  Iteration    2, particle 83, new swarm best. Train: 2.294e+01, Val: 2.155e+01\n",
      "18:45:03  Iteration    3, particle  2, new swarm best. Train: 1.694e+01, Val: 1.622e+01\n",
      "18:45:29  Iteration    4, particle 38, new swarm best. Train: 1.463e+01, Val: 4.868e+06\n",
      "18:45:32  Iteration    4, particle 42, new swarm best. Train: 6.983e+00, Val: 7.169e+00\n",
      "18:46:45  Iteration    7, particle  6, new swarm best. Train: 6.469e+00, Val: 6.367e+00\n",
      "18:47:35  Iteration    9, particle 13, new swarm best. Train: 6.450e+00, Val: 6.303e+00\n",
      "18:47:37  Iteration    9, particle 15, new swarm best. Train: 5.345e+00, Val: 5.284e+00\n",
      "18:47:40  Iteration    9, particle 74, new swarm best. Train: 4.175e+00, Val: 4.266e+00\n",
      "18:52:01  Iteration   20, particle 38, new swarm best. Train: 3.426e+00, Val: 3.905e+00\n"
     ]
    }
   ],
   "source": [
    "network = Feed_Forward_Neural_Network(nr_hidden_layers, nr_neurons_per_layer, input_features, output_features, \n",
    "                                      activation_function, output_activation, regularisation_strength)\n",
    "network.setup_pso(pso_param_dict, reinf_learning=reinforcement_learning, real_observations=real_observations, nr_processes=nr_processes)\n",
    "start = time.time()\n",
    "network.train_pso(nr_iterations, training_data_dict, std_penalty=std_penalty, verbatim=verbatim)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set plot variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard plots\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('trained_networks/best_model.h5')\n",
    "training_data_dict = pickle.load( open( \"trained_networks/best_model_training_data_dict.p\", \"rb\" ) )\n",
    "\n",
    "mode = 'train' # 'train', 'val, 'test'\n",
    "best_weights = 'val' # 'train', 'val'\n",
    "\n",
    "predicted_points = predict_points(model, training_data_dict, mode = mode, original_units=False)\n",
    "title = 'Inputs: {}\\n{:.1e} train points, {}'.format(', '.join(input_features), train_size, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get reinforcement learning plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig73 = get_ssfr_plot(model, training_data_dict, unit_dict, galaxies=None, title=None, data_type=mode)\n",
    "fig55 = get_smf_plot(model, training_data_dict, unit_dict, galaxies=None, title=None, data_type=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig73.savefig(fig_dir + 'ssfr_as_loss_func.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get standard pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig1 = get_pred_vs_real_scatterplot(model, training_data_dict, unit_dict, data_keys, 'Stellar_mass', pso=True, title=title, data_type=mode,\n",
    "                                   predicted_points = predicted_points, galaxies=galaxies)\n",
    "\n",
    "fig2 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, pso=True, predicted_feat = 'Stellar_mass', \n",
    "                                binning_feat = 'Halo_mass', title=title, data_type=mode,\n",
    "                                predicted_points = predicted_points)\n",
    "\n",
    "fig3 = get_halo_stellar_mass_plots(model, training_data_dict, unit_dict, pso=True, title=title, y_max = None, y_min = None,\n",
    "                                    x_min = None, x_max = None, data_type=mode, predicted_points = predicted_points)\n",
    "fig4 = get_stellar_mass_sfr_plots(model, training_data_dict, unit_dict, pso=True, title=title, y_max = None, y_min = None,\n",
    "                                    x_min = None, x_max = None, data_type=mode, predicted_points = predicted_points)\n",
    "fig5 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, pso=True, predicted_feat = 'SFR', \n",
    "                                binning_feat = 'Stellar_mass', title=title, data_type=mode,\n",
    "                                predicted_points = predicted_points)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6 = get_real_vs_pred_same_fig(model, training_data_dict, unit_dict, x_axis_feature='Halo_mass', \n",
    "                                 y_axis_feature = 'Stellar_mass', pso=True, title=title, data_type=mode, marker_size=20, predicted_points=predicted_points,\n",
    "                                 y_min=None, y_max=None, x_min=None, x_max=None)\n",
    "# fig7 = get_real_vs_pred_same_fig(model, training_data_dict, unit_dict, x_axis_feature='Stellar_mass', \n",
    "#                                  y_axis_feature = 'SFR', pso=True, title=title, data_type=mode, marker_size=20,\n",
    "#                                  y_min=None, y_max=None, x_min=None, x_max=None)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6.savefig(fig_dir + 'proof_of_concept_3x3_net_one_output_no_weighing.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "network.pso_swarm.set_best_weights('train')\n",
    "norm_score = network.pso_swarm.evaluate_model(mode)\n",
    "tot_score = norm_score\n",
    "model = network.model\n",
    "title = 'Inputs: %s\\ntest mse %.3e, %s data' % (', '.join(input_features), tot_score, mode)\n",
    "\n",
    "fig1 = get_pred_vs_real_scatterplot(model, training_data_dict, unit_dict, data_keys, 'SFR', title=title, mode=mode)\n",
    "fig2 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, predicted_feat = 'Stellar_mass', \n",
    "                                binning_feat = 'Halo_mass', title=title, mode=mode)\n",
    "fig3 = get_scatter_comparison_plots(model, training_data_dict, unit_dict, x_axis_feature = 'Halo_mass', \n",
    "                                    y_axis_feature = 'Stellar_mass', title=title, y_max = None, y_min = None,\n",
    "                                    x_min = None, x_max = None, mode=mode)\n",
    "fig4 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, 'SFR', \n",
    "                                binning_feat = 'Stellar_mass', title=title, mode=mode)\n",
    "fig5 = get_scatter_comparison_plots(model, training_data_dict, unit_dict, x_axis_feature = 'Halo_mass', \n",
    "                                    y_axis_feature = 'SFR', title=title, y_max = 10, y_min = None,\n",
    "                                    x_min = None, x_max = None, mode=mode)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nBins = 8\n",
    "bin_edges = np.linspace(halo_min_mass, halo_max_mass, nBins+1)\n",
    "\n",
    "predictedY = model.predict(x_test)\n",
    "\n",
    "for i, feat in enumerate(output_features):\n",
    "    \n",
    "    \n",
    "    ### Plot 1\n",
    "    fig = plt.figure(figsize=(16,16))\n",
    "    ax = plt.subplot(211)\n",
    "    plt.plot(y_test[:,i], y_test[:,i], 'k.')\n",
    "    plt.plot(predictedY[:,i], y_test[:,i], 'g.')\n",
    "    plt.ylabel('True %s %s' % (feat, unit_dict[feat]), fontsize=15)\n",
    "    plt.xlabel('Predicted %s %s' % (feat, unit_dict[feat]), fontsize=15)\n",
    "    plt.legend(['Ideal result', 'predicted ' + feat], loc='upper center')\n",
    "    plt.title('nIterations: %d, training set size: %d, test mse score: %.2e\\n' % (nIterations, \n",
    "        train_size, testScore) + \n",
    "        '%d input feature(s): [%s]\\n%d output feature(s): [%s]\\n%d test data points (test) shown' % (\n",
    "        len(input_features), ', '.join(input_features), len(output_features), ', '.join(output_features),\n",
    "        test_size), y=1.03, fontsize=20)\n",
    "    plt.show\n",
    "        \n",
    "    if save_figs:\n",
    "        fig.savefig(fig_dir+'pso_output_scatter_%d_plot_from_' % (i+1)+'_and_'.join(input_features)+'_to_'+\n",
    "            '_and_'.join(output_features)+'_with_'+param_string+'.png', bbox_inches = 'tight')\n",
    "    \n",
    "    ### Plot 2 - boxplot\n",
    "    \n",
    "    # bin_means contain (0: mean of the binned values, 1: bin edges, 2: numbers pointing each example to a bin)\n",
    "    bin_means_true = stats.binned_statistic(x_test[:,i], y_test[:,i], bins=bin_edges)\n",
    "    bin_means_pred = stats.binned_statistic(x_test[:,i], predictedY[:,i].flatten(), bins=bin_edges)\n",
    "    bin_centers = []\n",
    "    for iBin in range(nBins):\n",
    "        bin_centers.append((bin_means_true[1][iBin] + bin_means_true[1][iBin+1]) / 2)\n",
    "    sorted_true_y_data = []\n",
    "    sorted_pred_y_data = []\n",
    "    for iBin in range(1,nBins+1):\n",
    "        sorted_true_y_data.append(y_test[bin_means_true[2] == iBin, i])\n",
    "        sorted_pred_y_data.append(predictedY[bin_means_pred[2] == iBin,i])\n",
    "    \n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax = plt.subplot(212)\n",
    "\n",
    "    bin_pos = np.array([-2,-1]) # (because this makes it work)\n",
    "    x_label_centers = []\n",
    "    for iBin in range(nBins):\n",
    "        # Every boxplot adds 2 boxes, one from the true data and one from the predicted data\n",
    "        bin_pos += 3 \n",
    "        plt.boxplot([sorted_true_y_data[iBin], sorted_pred_y_data[iBin]] , positions = bin_pos, widths = 0.9)\n",
    "        x_label_centers.append(np.mean(bin_pos))\n",
    "    \n",
    "    plt.ylabel('%s %s' % (feat, unit_dict[feat]), fontsize=15)\n",
    "    plt.xlabel('True Halo mass log($M_{G}/M_{S}$)', fontsize=15)\n",
    "    ax.set_xlim(left=x_label_centers[0]-2, right=x_label_centers[-1]+2)\n",
    "    #xlim(0,bin_pos[1] + 1)\n",
    "    plt.xticks(x_label_centers, bin_centers) TODO fixa siffrorna\n",
    "    plt.text(12,7,'Left: true data. Right: predicted data.', fontsize=20)\n",
    "    \n",
    "    if feat == 'SFR':\n",
    "        ax.axhline(y=0, linestyle='--')\n",
    "    \n",
    "    #plt.title('nIterations: %d, training set size: %d, test mse score: %.2e\\n' % (nIterations, \n",
    "    #    train_size, testScore) + \n",
    "    #    '%d input feature(s): [%s]\\n%d output feature(s): [%s]\\n%d test data points (test) shown' % (\n",
    "    #    len(input_features), ', '.join(input_features), len(output_features), ', '.join(output_features),\n",
    "    #    test_size), y=1.03, fontsize=20)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    if save_figs:\n",
    "        fig.savefig(fig_dir+'pso_output_boxplot_%d_from_' % (i+1)+'_and_'.join(input_features)+'_to_'+\n",
    "            '_and_'.join(output_features)+'_with_'+param_string+'.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for loss\n",
    "%matplotlib inline\n",
    "fig = plt.figure(5, figsize=(8,8))\n",
    "plt.plot(trainingScoreHistory, 'b')\n",
    "plt.plot(validationScoreHistory, 'r')\n",
    "plt.yscale('log')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
