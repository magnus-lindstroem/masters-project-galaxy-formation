{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "from os.path import expanduser\n",
    "home_dir = expanduser(\"~\")\n",
    "module_path = home_dir + '/code/modules/'\n",
    "fig_dir = 'figures/'\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "import time\n",
    "import cv2\n",
    "import datetime\n",
    "import importlib\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "from operator import itemgetter\n",
    "from keras.models import load_model\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport distance_metrics\n",
    "%aimport data_processing\n",
    "%aimport plotting\n",
    "# %aimport pso\n",
    "%aimport pso_parallel_training_queue\n",
    "from distance_metrics import minkowski_distance\n",
    "from data_processing import *\n",
    "from plotting import *\n",
    "# from pso import *\n",
    "from pso_parallel_training_queue import *\n",
    "\n",
    "np.random.seed(999)\n",
    "random.seed(999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set plot variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard plots\n",
    "model_name = '6x6_tanh_xi10_loss_point9_cutoff_no_empty_bin_punish_nbin_weighted_loss'\n",
    "mode_of_progress = 'validation' # 'training', 'validation'\n",
    "\n",
    "data_type = 'val' # 'train', 'val, 'test'\n",
    "iteration = '691'\n",
    "\n",
    "plot_full_range = True\n",
    "\n",
    "model = load_model('trained_networks/{}/{}_best/iter_{}.h5'.format(model_name, mode_of_progress, iteration))\n",
    "training_data_dict = pickle.load(open('trained_networks/{}/{}_best/training_data_dict.p'.format(model_name, mode_of_progress), 'rb'))\n",
    "\n",
    "predicted_points = predict_points(model, training_data_dict, mode=data_type, original_units=False)\n",
    "title = 'Iteration {}, best {} weights, {} data points shown'.format(iteration, mode_of_progress, data_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get reinforcement learning plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig858 = get_smf_ssfr_fq_plot(model, training_data_dict, galaxies=None, title=title, data_type=data_type, full_range=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig73 = get_ssfr_plot(model, training_data_dict, unit_dict, galaxies=None, title=None, data_type=data_type, full_range=plot_full_range)\n",
    "fig55 = get_smf_plot(model, training_data_dict, unit_dict, galaxies=None, title=None, data_type=data_type, full_range=plot_full_range)\n",
    "fig33 = get_fq_plot(model, training_data_dict, unit_dict, galaxies=None, title=None, data_type=data_type, full_range=plot_full_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig73.savefig(fig_dir + 'ssfr_plot_3_loss_func_4x4_400_iters_Z00.png', bbox_inches = 'tight')\n",
    "fig55.savefig(fig_dir + 'smf_plot_3_loss_func_4x4_400_iters_Z00.png', bbox_inches = 'tight')\n",
    "fig33.savefig(fig_dir + 'fq_plot_3_loss_func_4x4_400_iters_Z00.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get standard pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = get_pred_vs_real_scatterplot(model, training_data_dict, unit_dict, data_keys, 'Stellar_mass', pso=True, title=title, data_type=mode,\n",
    "                                   predicted_points = predicted_points, galaxies=galaxies)\n",
    "\n",
    "fig2 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, pso=True, predicted_feat = 'Stellar_mass', \n",
    "                                binning_feat = 'Halo_mass', title=title, data_type=mode,\n",
    "                                predicted_points = predicted_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig3 = get_halo_stellar_mass_plots(model, training_data_dict, no_true_plots=True, title=title, y_max = None, y_min = None,\n",
    "                                    x_min = None, x_max = None, data_type=data_type, predicted_points = predicted_points)\n",
    "\n",
    "fig4 = get_stellar_mass_sfr_plots(model, training_data_dict, no_true_plots=True, title=title, y_max = None, y_min = None,\n",
    "                                    x_min = None, x_max = None, data_type=data_type, predicted_points = predicted_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3.savefig(fig_dir + 'halo_stellar_mass_plot_6x6_tanh_xi10_loss_point9_cutoff_no_empty_bin_punish_nbin_weighted_loss.png', bbox_inches = 'tight')\n",
    "fig4.savefig(fig_dir + 'stellar_mass_sfr_plot_6x6_tanh_xi10_loss_point9_cutoff_no_empty_bin_punish_nbin_weighted_loss.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig5 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, pso=True, predicted_feat = 'SFR', \n",
    "                                binning_feat = 'Stellar_mass', title=title, data_type=mode,\n",
    "                                predicted_points = predicted_points)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6 = get_real_vs_pred_same_fig(model, training_data_dict, unit_dict, x_axis_feature='Halo_mass', \n",
    "                                 y_axis_feature = 'Stellar_mass', pso=True, title=title, data_type=mode, marker_size=20, predicted_points=predicted_points,\n",
    "                                 y_min=None, y_max=None, x_min=None, x_max=None)\n",
    "# fig7 = get_real_vs_pred_same_fig(model, training_data_dict, unit_dict, x_axis_feature='Stellar_mass', \n",
    "#                                  y_axis_feature = 'SFR', pso=True, title=title, data_type=mode, marker_size=20,\n",
    "#                                  y_min=None, y_max=None, x_min=None, x_max=None)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6.savefig(fig_dir + 'proof_of_concept_3x3_net_one_output_no_weighing.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create progress figures and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'lin_loss_func_slope_10_point9_cutoff_empty_bin_punish'\n",
    "\n",
    "modes_of_progress = ['validation', 'training'] # 'training', 'validation'\n",
    "data_types = ['val', 'train']\n",
    "\n",
    "plot_types = ['smf', 'ssfr', 'fq']\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "frame_rate = 1\n",
    "\n",
    "for mode_of_progress, data_type in zip(modes_of_progress, data_types):\n",
    "    \n",
    "    model_dir = 'trained_networks/{}/{}_best/'.format(model_name, mode_of_progress)\n",
    "    model_fig_dir = 'trained_networks/{}/figures_{}_weights/{}_data/'.format(model_name, mode_of_progress, data_type)\n",
    "\n",
    "    model_list = []\n",
    "    for file in os.listdir(model_dir):\n",
    "        if file == 'training_data_dict.p':\n",
    "            training_data_dict_model = pickle.load(open(model_dir + file, 'rb'))\n",
    "        else:\n",
    "            nr = file[5:-3]\n",
    "            model_list.append([file, int(nr)])\n",
    "\n",
    "    model_list.sort(key=itemgetter(1))\n",
    "\n",
    "    for model_file, iteration in model_list:\n",
    "        model = load_model(model_dir + model_file)\n",
    "\n",
    "        title = 'Iteration {}, best {} weights, {} data points shown'.format(iteration, mode_of_progress, data_type)\n",
    "        if 'fq' in plot_types:\n",
    "            fq_file_path = model_fig_dir + 'fq/' + 'iteration_{}.png'.format(iteration)\n",
    "            get_fq_plot(model, training_data_dict_model, galaxies=None, title=title, data_type=data_type, full_range=True, save=True, file_path=fq_file_path)\n",
    "            \n",
    "        if 'smf' in plot_types:\n",
    "            smf_file_path = model_fig_dir + 'smf/' + 'iteration_{}.png'.format(iteration)\n",
    "            get_smf_plot(model, training_data_dict_model, galaxies=None, title=title, data_type=data_type, full_range=True, save=True, file_path=smf_file_path)\n",
    "            \n",
    "        if 'ssfr' in plot_types:\n",
    "            ssfr_file_path = model_fig_dir + 'ssfr/' + 'iteration_{}.png'.format(iteration)\n",
    "            get_ssfr_plot(model, training_data_dict_model, galaxies=None, title=title, data_type=data_type, full_range=True, save=True, file_path=ssfr_file_path)\n",
    "            \n",
    "    for plot_type in plot_types:\n",
    "        image_folder = 'trained_networks/{}/figures_{}_weights/{}_data/{}/'.format(model_name, weights, data_type, plot_type)\n",
    "        video_path = image_folder + 'progress_video.avi'\n",
    "\n",
    "        images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "        images_with_nrs = []\n",
    "        for image in images:\n",
    "            number = image.split('_')\n",
    "            number = number[-1][:-4]\n",
    "            images_with_nrs.append([image, int(number)])\n",
    "\n",
    "        images_with_nrs.sort(key=itemgetter(1))\n",
    "\n",
    "        images = [image_folder + items[0] for items in images_with_nrs]\n",
    "\n",
    "        frame = cv2.imread(images[0])\n",
    "        height, width, layers = frame.shape\n",
    "\n",
    "        video = cv2.VideoWriter(video_path, fourcc, frame_rate, (width,height))\n",
    "\n",
    "        for image in images:\n",
    "            img = cv2.imread(image)\n",
    "            video.write(img)\n",
    "\n",
    "        video.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie with all three loss conditions in same fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '6x6_2.9e+04points_redshifts00_tanh_exp30_loss_minFilledBinFrac000_fq-ssfr-smf-shm_weights_1-1-1-3'\n",
    "training_material = 'mock_observations' # 'mock_observations', 'real_observations'\n",
    "modes_of_progress = ['validation'] # 'training', 'validation'\n",
    "data_types = ['val'] # 'train', 'val'\n",
    "produce_images = False\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "frame_rate = 1\n",
    "\n",
    "# trained_networks/pso_trained/mock_observations/6x6_2.9e+04points_redshifts00_tanh_exp30_loss_minFilledBinFrac000_fq-ssfr-smf-shm_weights_0-1-1-2/validation_best/\n",
    "\n",
    "model_dir = '{}/trained_networks/pso_trained/{}/{}/'.format(home_dir, training_material, model_name)\n",
    "\n",
    "for mode_of_progress, data_type in zip(modes_of_progress, data_types):\n",
    "    mode_of_progress_networks_dir = '{}{}_best/'.format(model_dir, mode_of_progress)\n",
    "    model_fig_dir = '{}figures_{}_weights/{}_data/all_losses/'.format(model_dir, mode_of_progress, data_type)\n",
    "    \n",
    "    if produce_images:\n",
    "    \n",
    "        model_list = []\n",
    "        for file in os.listdir(mode_of_progress_networks_dir):\n",
    "            if file == 'training_data_dict.p':\n",
    "                training_data_dict_model = pickle.load(open(mode_of_progress_networks_dir + file, 'rb'))\n",
    "            else:\n",
    "                nr = file[5:-3]\n",
    "                model_list.append([file, int(nr)])\n",
    "\n",
    "        model_list.sort(key=itemgetter(1))\n",
    "\n",
    "        for model_file, iteration in model_list:\n",
    "            model = load_model(mode_of_progress_networks_dir + model_file)\n",
    "\n",
    "            title = 'Iteration {}, best {} weights, {} data points shown'.format(iteration, mode_of_progress, data_type)\n",
    "            fig_file_path = model_fig_dir + 'iteration_{}.png'.format(iteration)\n",
    "            get_smf_ssfr_fq_plot(model, training_data_dict_model, galaxies=None, title=title, data_type=data_type, full_range=True, save=True, file_path=fig_file_path)\n",
    "\n",
    "    video_path = model_fig_dir + 'progress_video5.avi'\n",
    "\n",
    "    images = [img for img in os.listdir(model_fig_dir) if img.endswith(\".png\")]\n",
    "    images_with_nrs = []\n",
    "    for image in images:\n",
    "        number = image.split('_')\n",
    "        number = number[-1][:-4]\n",
    "        images_with_nrs.append([image, int(number)])\n",
    "\n",
    "    images_with_nrs.sort(key=itemgetter(1))\n",
    "\n",
    "    images = [model_fig_dir + items[0] for items in images_with_nrs]\n",
    "\n",
    "    frame = cv2.imread(images[0])\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    video = cv2.VideoWriter(video_path, fourcc, frame_rate, (width,height))\n",
    "\n",
    "    for image in images:\n",
    "        img = cv2.imread(image)\n",
    "        video.write(img)\n",
    "\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance between new high scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_name = '4x4_relu_xi10_loss_point9_cutoff_no_empty_bin_punish'\n",
    "\n",
    "model_dir = 'trained_networks/{}/'.format(model_name)\n",
    "os.makedirs(os.path.dirname(model_dir + 'swarm_best_distance_moved.p'), exist_ok=True)\n",
    "distance_dict = pickle.load(open(model_dir + 'swarm_best_distance_moved.p', 'rb'))\n",
    "\n",
    "print(distance_dict.keys())\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.plot(distance_dict['swarm_best_distance_moved_p_point_one'])\n",
    "plt.plot(distance_dict['swarm_best_distance_moved_p_one'])\n",
    "plt.plot(distance_dict['swarm_best_distance_moved_p_two'])\n",
    "plt.plot(distance_dict['swarm_best_distance_moved_p_inf'])\n",
    "plt.legend(['p = 0.1', 'p = 1', 'p = 2', 'p = inf'], loc='upper right', fontsize='xx-large')\n",
    "# plt.plot([dist[1][0] for dist in distance_dict['swarm_best_distance_moved_p_point_one']])\n",
    "plt.yscale('log')\n",
    "\n",
    "fig.savefig(fig_dir + '4x4_relu_xi10_loss_point9_cutoff_no_empty_bin_punish.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(distance_dict['swarm_best_distance_moved_p_one'][10:])/np.array(distance_dict['swarm_best_distance_moved_p_point_one'][10:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interparticle distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'testing'\n",
    "\n",
    "dict_dir = 'trained_networks/{}/interparticle_distances/'.format(model_name)\n",
    "dict_list = []\n",
    "for file in os.listdir(dict_dir):\n",
    "    nr = file[5:-2]\n",
    "    dict_list.append([file, int(nr)])\n",
    "\n",
    "dict_list.sort(key=itemgetter(1))\n",
    "\n",
    "\n",
    "p_point_one_list = []\n",
    "p_one_list = []\n",
    "p_two_list = []\n",
    "\n",
    "for dict_file, iteration in dict_list:\n",
    "    distance_dict = pickle.load(open(dict_dir + dict_file, 'rb'))\n",
    "    \n",
    "    p_point_one = []\n",
    "    p_one = []\n",
    "    p_two = []\n",
    "    \n",
    "    for i in range(np.shape(distance_dict['p_point_one'])[0]):\n",
    "        for j in range(i+1, np.shape(distance_dict['p_point_one'])[1]):\n",
    "            p_point_one.append(distance_dict['p_point_one'][i,j])\n",
    "    for i in range(np.shape(distance_dict['p_one'])[0]):\n",
    "        for j in range(i+1, np.shape(distance_dict['p_one'])[1]):\n",
    "            p_one.append(distance_dict['p_one'][i,j])\n",
    "    for i in range(np.shape(distance_dict['p_two'])[0]):\n",
    "        for j in range(i+1, np.shape(distance_dict['p_two'])[1]):\n",
    "            p_two.append(distance_dict['p_two'][i,j])\n",
    "            \n",
    "    p_point_one_list.append(p_point_one)\n",
    "    p_one_list.append(p_one)\n",
    "    p_two_list.append(p_two)\n",
    "    \n",
    "\n",
    "for interpart_dist_dict in dict_list:\n",
    "    \n",
    "    print(interpart_dist_dict)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(model_dir + 'interparticle_distances/iter_{}.p'), exist_ok=True)\n",
    "distance_dict = pickle.load(open(model_dir + 'interparticle_distances.p', 'rb'))\n",
    "\n",
    "\n",
    "print(distance_dict.keys())\n",
    "print(distance_dict['p_point_one'])\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.plot(distance_dict['p_point_one'], 'bo')\n",
    "plt.plot(distance_dict['p_one'], 'rx')\n",
    "plt.plot(distance_dict['p_two'], 'g.')\n",
    "plt.legend(['p = 0.1', 'p = 1', 'p = 2'], loc='upper right', fontsize='xx-large')\n",
    "# plt.plot([dist[1][0] for dist in distance_dict['swarm_best_distance_moved_p_point_one']])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2],[3,4],[10,2]]\n",
    "b = minkowski_distance(a, p=20)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.power(0, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non parallel PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "network.pso_swarm.set_best_weights('train')\n",
    "norm_score = network.pso_swarm.evaluate_model(mode)\n",
    "tot_score = norm_score\n",
    "model = network.model\n",
    "title = 'Inputs: %s\\ntest mse %.3e, %s data' % (', '.join(input_features), tot_score, mode)\n",
    "\n",
    "fig1 = get_pred_vs_real_scatterplot(model, training_data_dict, unit_dict, data_keys, 'SFR', title=title, mode=mode)\n",
    "fig2 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, predicted_feat = 'Stellar_mass', \n",
    "                                binning_feat = 'Halo_mass', title=title, mode=mode)\n",
    "fig3 = get_scatter_comparison_plots(model, training_data_dict, unit_dict, x_axis_feature = 'Halo_mass', \n",
    "                                    y_axis_feature = 'Stellar_mass', title=title, y_max = None, y_min = None,\n",
    "                                    x_min = None, x_max = None, mode=mode)\n",
    "fig4 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, 'SFR', \n",
    "                                binning_feat = 'Stellar_mass', title=title, mode=mode)\n",
    "fig5 = get_scatter_comparison_plots(model, training_data_dict, unit_dict, x_axis_feature = 'Halo_mass', \n",
    "                                    y_axis_feature = 'SFR', title=title, y_max = 10, y_min = None,\n",
    "                                    x_min = None, x_max = None, mode=mode)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train new network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General parameters\n",
    "total_set_size = 2.9e4 # how many examples will be used for training+validation+testing\n",
    "train_size = 2e4\n",
    "val_size = .5e4\n",
    "test_size = .4e4\n",
    "input_features = ['Halo_mass', 'Halo_mass_peak', 'Scale_peak_mass', 'Scale_half_mass', 'Halo_growth_rate']#, 'Redshift']\n",
    "output_features = ['Stellar_mass', 'SFR']\n",
    "redshifts = [0]#,.1,.2,.5,1,2,3,4,6,8]\n",
    "same_n_points_per_redshift = False # if using the smf in the objective function, must be false!\n",
    "outputs_to_weigh = ['Stellar_mass']\n",
    "weigh_by_redshift = True\n",
    "\n",
    "reinforcement_learning = True\n",
    "real_observations = False\n",
    "\n",
    "verbatim = True\n",
    "\n",
    "network_name = 'testing2'\n",
    "# network_name = '{}'.format(datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "save_all_nets = True\n",
    "\n",
    "### Network parameters\n",
    "nr_hidden_layers = 4\n",
    "activation_function = 'tanh'\n",
    "output_activation = {'SFR': None, 'Stellar_mass': None}\n",
    "nr_neurons_per_layer = 4\n",
    "regularisation_strength = 1e-2\n",
    "std_penalty = False\n",
    "norm = {'input': 'zero_mean_unit_std',\n",
    "        'output': 'zero_mean_unit_std'} # 'none',   'zero_mean_unit_std',   'zero_to_one'\n",
    "\n",
    "### PSO parameters\n",
    "nr_processes = 30\n",
    "nr_iterations = 1000\n",
    "min_std_tol = 0.01                # minimum allowed std for any parameter\n",
    "pso_param_dict = {\n",
    "    'nr_particles': 3 * nr_processes,\n",
    "    'inertia_weight_start': 1.4,\n",
    "    'inertia_weight_min': 0.3,\n",
    "    'exploration_iters': 600,\n",
    "    'patience': 10000,\n",
    "    'patience_parameter': 'train',\n",
    "    'restart_check_interval': 200\n",
    "}\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the selected galaxyfile\n",
    "galaxies, data_keys, unit_dict = load_galfiles(redshifts=redshifts, equal_numbers=same_n_points_per_redshift)\n",
    "    \n",
    "# prepare the training data\n",
    "training_data_dict = divide_train_data(galaxies, data_keys, input_features, output_features, redshifts, weigh_by_redshift, outputs_to_weigh,\n",
    "                                       int(total_set_size), train_size=int(train_size), val_size=int(val_size), test_size=int(test_size), pso=True)\n",
    "training_data_dict = normalise_data(training_data_dict, norm, pso=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network = Feed_Forward_Neural_Network(nr_hidden_layers, nr_neurons_per_layer, input_features, output_features, \n",
    "                                      activation_function, output_activation, regularisation_strength, network_name)\n",
    "network.setup_pso(pso_param_dict, reinf_learning=reinforcement_learning, real_observations=real_observations, nr_processes=nr_processes)\n",
    "network.train_pso(nr_iterations, training_data_dict, std_penalty=std_penalty, verbatim=verbatim, save_all_networks=save_all_nets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
