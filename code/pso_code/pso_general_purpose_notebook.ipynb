{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "from os.path import expanduser\n",
    "home_dir = expanduser(\"~\")\n",
    "module_path = home_dir + '/code/modules/'\n",
    "fig_dir = 'figures/'\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "import time\n",
    "import datetime\n",
    "import importlib\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "\n",
    "import model_management\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data_processing\n",
    "%aimport plotting\n",
    "%aimport keras_objects\n",
    "# %aimport pso\n",
    "%aimport pso_parallel_training_queue\n",
    "from data_processing import *\n",
    "from plotting import *\n",
    "from keras_objects import *\n",
    "# from pso import *\n",
    "from pso_parallel_training_queue import *\n",
    "\n",
    "np.random.seed(999)\n",
    "random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General parameters\n",
    "total_set_size = 3e2 # how many examples will be used for training+validation+testing\n",
    "train_size = 1e2\n",
    "val_size = 1e2\n",
    "test_size = 1e2\n",
    "input_features = ['Halo_mass']#, 'Halo_mass_peak', 'Scale_peak_mass', 'Scale_half_mass', 'Redshift']\n",
    "output_features = ['Stellar_mass']#, 'SFR']\n",
    "redshifts = [0,.1,.2,.5,1,2,3,4,6,8]\n",
    "same_n_points_per_redshift = True\n",
    "outputs_to_weigh = ['Stellar_mass']\n",
    "weigh_by_redshift = True\n",
    "\n",
    "verbatim = True\n",
    "\n",
    "### Network parameters\n",
    "nr_hidden_layers = 6\n",
    "activation_function = 'tanh'\n",
    "output_activation = {'SFR': None, 'Stellar_mass': None}\n",
    "nr_neurons_per_layer = 6\n",
    "regularisation_strength = 1e-2\n",
    "std_penalty = False\n",
    "norm = {'input': 'zero_mean_unit_std',\n",
    "        'output': 'zero_mean_unit_std'} # 'none',   'zero_mean_unit_std',   'zero_to_one'\n",
    "\n",
    "### PSO parameters\n",
    "nr_processes = 1\n",
    "nr_iterations = 5000\n",
    "x_min = -10\n",
    "x_max = 10\n",
    "alpha = 1\n",
    "delta_t = 1\n",
    "c1 = 2\n",
    "c2 = 2\n",
    "inertia_weight_start = 1.4\n",
    "inertia_weight_min = 0.3\n",
    "exploration_fraction = 0.8            # start making sure that the network did not converge to a local minimum\n",
    "min_std_tol = 0.01                # minimum allowed std for any parameter\n",
    "pso_param_dict = {\n",
    "    'nr_particles': nr_processes,\n",
    "    'patience': 2000,\n",
    "    'patience_parameter': 'train',\n",
    "    'restart_check_interval': 200\n",
    "}\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the selected galaxyfile\n",
    "galaxies, data_keys, unit_dict = load_galfiles(redshifts=redshifts, equal_numbers=same_n_points_per_redshift)\n",
    "    \n",
    "# prepare the training data\n",
    "training_data_dict = divide_train_data(galaxies, data_keys, input_features, output_features, redshifts, weigh_by_redshift, outputs_to_weigh,\n",
    "                                       int(total_set_size), train_size=int(train_size), val_size=int(val_size), test_size=int(test_size), pso=True)\n",
    "training_data_dict = normalise_data(training_data_dict, norm, pso=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process-1  online\n",
      "input queued  0\n",
      "Process-1  received a job. Particle nr:  0\n",
      "after get weights\n",
      "<bound method Container.set_weights of <keras.engine.training.Model object at 0x7ff07ced9048>>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d538f718faf7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_pso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpso_param_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_pso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnr_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_penalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd_penalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbatim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbatim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/modules/pso_parallel_training_queue.py\u001b[0m in \u001b[0;36mtrain_pso\u001b[0;34m(self, nr_iterations, training_data_dict, speed_check, std_penalty, verbatim)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         self.pso_swarm.train_network(nr_iterations, training_data_dict,\n\u001b[0;32m---> 33\u001b[0;31m                                      std_penalty, speed_check, verbatim)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/modules/pso_parallel_training_queue.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(self, nr_iterations, training_data_dict, std_penalty, speed_check, verbatim)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticle_nr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                         \u001b[0mparticle_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparticle_nr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results received'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_particle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network = Feed_Forward_Neural_Network(nr_hidden_layers, nr_neurons_per_layer, input_features, output_features, \n",
    "                                      activation_function, output_activation, regularisation_strength)\n",
    "network.setup_pso(pso_param_dict)\n",
    "start = time.time()\n",
    "network.train_pso(nr_iterations, training_data_dict, std_penalty=std_penalty, verbatim=verbatim)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0.1, 0.2, 0.5, 1, 2, 3, 4, 6, 8]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_dict['unique_redshifts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time elapsed with CPUs (train size {:d}): {:.0f}s'.format(train_size, (end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Time elapsed with GPUs (train size {:d}): {:.0f}s'.format(train_size, (end-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get standard pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard plots\n",
    "\n",
    "mode = 'train' # 'train', 'val, 'test'\n",
    "best_weights = 'train' # 'train', 'val, 'test'\n",
    "\n",
    "network.pso_swarm.set_best_weights(best_weights)\n",
    "norm_score = network.pso_swarm.evaluate_model(mode)\n",
    "tot_score = norm_score\n",
    "model = network.model\n",
    "\n",
    "output_dict = {\n",
    "    'Stellar_mass': training_data_dict['input_'+mode+'_dict']['main_input'][:, 0]#,\n",
    "#    'SFR': training_data_dict['input_'+mode+'_dict']['main_input'][:, 1]\n",
    "}\n",
    "weights_dict = {\n",
    "    'Stellar_mass': training_data_dict[mode+'_weights'][:, 0]#,\n",
    "#    'SFR': training_data_dict[mode+'_weights'][:, 1]\n",
    "}\n",
    "\n",
    "tot_score = norm_score\n",
    "predicted_points = predict_points(model, training_data_dict, mode = mode, original_units=True)\n",
    "title = 'Inputs: {}\\n{:.1e} train points, {} mse {:.3e}, {} data'.format(', '.join(input_features), train_size, mode, tot_score, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(model.get_weights()[0])\n",
    "hej = np.array(model.get_weights())\n",
    "print(hej)\n",
    "print(np.shape(hej))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig1 = get_pred_vs_real_scatterplot(model, training_data_dict, unit_dict, data_keys, 'Stellar_mass', pso=True, title=title, data_type=mode,\n",
    "                                   predicted_points = predicted_points, galaxies=galaxies)\n",
    "\n",
    "fig2 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, pso=True, predicted_feat = 'Stellar_mass', \n",
    "                                binning_feat = 'Halo_mass', title=title, data_type=mode,\n",
    "                                predicted_points = predicted_points)\n",
    "\n",
    "fig3 = get_halo_stellar_mass_plots(model, training_data_dict, unit_dict, pso=True, title=title, y_max = None, y_min = None,\n",
    "                                    x_min = None, x_max = None, data_type=mode, predicted_points = predicted_points)\n",
    "fig4 = get_stellar_mass_sfr_plots(model, training_data_dict, unit_dict, pso=True, title=title, y_max = None, y_min = None,\n",
    "                                    x_min = None, x_max = None, data_type=mode, predicted_points = predicted_points)\n",
    "fig5 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, pso=True, predicted_feat = 'SFR', \n",
    "                                binning_feat = 'Stellar_mass', title=title, data_type=mode,\n",
    "                                predicted_points = predicted_points)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6 = get_real_vs_pred_same_fig(model, training_data_dict, unit_dict, x_axis_feature='Halo_mass', \n",
    "                                 y_axis_feature = 'Stellar_mass', pso=True, title=title, data_type=mode, marker_size=20, predicted_points=predicted_points,\n",
    "                                 y_min=None, y_max=None, x_min=None, x_max=None)\n",
    "# fig7 = get_real_vs_pred_same_fig(model, training_data_dict, unit_dict, x_axis_feature='Stellar_mass', \n",
    "#                                  y_axis_feature = 'SFR', pso=True, title=title, data_type=mode, marker_size=20,\n",
    "#                                  y_min=None, y_max=None, x_min=None, x_max=None)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6.savefig(fig_dir + 'proof_of_concept_3x3_net_one_output_no_weighing.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "network.pso_swarm.set_best_weights('train')\n",
    "norm_score = network.pso_swarm.evaluate_model(mode)\n",
    "tot_score = norm_score\n",
    "model = network.model\n",
    "title = 'Inputs: %s\\ntest mse %.3e, %s data' % (', '.join(input_features), tot_score, mode)\n",
    "\n",
    "fig1 = get_pred_vs_real_scatterplot(model, training_data_dict, unit_dict, data_keys, 'SFR', title=title, mode=mode)\n",
    "fig2 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, predicted_feat = 'Stellar_mass', \n",
    "                                binning_feat = 'Halo_mass', title=title, mode=mode)\n",
    "fig3 = get_scatter_comparison_plots(model, training_data_dict, unit_dict, x_axis_feature = 'Halo_mass', \n",
    "                                    y_axis_feature = 'Stellar_mass', title=title, y_max = None, y_min = None,\n",
    "                                    x_min = None, x_max = None, mode=mode)\n",
    "fig4 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, 'SFR', \n",
    "                                binning_feat = 'Stellar_mass', title=title, mode=mode)\n",
    "fig5 = get_scatter_comparison_plots(model, training_data_dict, unit_dict, x_axis_feature = 'Halo_mass', \n",
    "                                    y_axis_feature = 'SFR', title=title, y_max = 10, y_min = None,\n",
    "                                    x_min = None, x_max = None, mode=mode)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nBins = 8\n",
    "bin_edges = np.linspace(halo_min_mass, halo_max_mass, nBins+1)\n",
    "\n",
    "predictedY = model.predict(x_test)\n",
    "\n",
    "for i, feat in enumerate(output_features):\n",
    "    \n",
    "    \n",
    "    ### Plot 1\n",
    "    fig = plt.figure(figsize=(16,16))\n",
    "    ax = plt.subplot(211)\n",
    "    plt.plot(y_test[:,i], y_test[:,i], 'k.')\n",
    "    plt.plot(predictedY[:,i], y_test[:,i], 'g.')\n",
    "    plt.ylabel('True %s %s' % (feat, unit_dict[feat]), fontsize=15)\n",
    "    plt.xlabel('Predicted %s %s' % (feat, unit_dict[feat]), fontsize=15)\n",
    "    plt.legend(['Ideal result', 'predicted ' + feat], loc='upper center')\n",
    "    plt.title('nIterations: %d, training set size: %d, test mse score: %.2e\\n' % (nIterations, \n",
    "        train_size, testScore) + \n",
    "        '%d input feature(s): [%s]\\n%d output feature(s): [%s]\\n%d test data points (test) shown' % (\n",
    "        len(input_features), ', '.join(input_features), len(output_features), ', '.join(output_features),\n",
    "        test_size), y=1.03, fontsize=20)\n",
    "    plt.show\n",
    "        \n",
    "    if save_figs:\n",
    "        fig.savefig(fig_dir+'pso_output_scatter_%d_plot_from_' % (i+1)+'_and_'.join(input_features)+'_to_'+\n",
    "            '_and_'.join(output_features)+'_with_'+param_string+'.png', bbox_inches = 'tight')\n",
    "    \n",
    "    ### Plot 2 - boxplot\n",
    "    \n",
    "    # bin_means contain (0: mean of the binned values, 1: bin edges, 2: numbers pointing each example to a bin)\n",
    "    bin_means_true = stats.binned_statistic(x_test[:,i], y_test[:,i], bins=bin_edges)\n",
    "    bin_means_pred = stats.binned_statistic(x_test[:,i], predictedY[:,i].flatten(), bins=bin_edges)\n",
    "    bin_centers = []\n",
    "    for iBin in range(nBins):\n",
    "        bin_centers.append((bin_means_true[1][iBin] + bin_means_true[1][iBin+1]) / 2)\n",
    "    sorted_true_y_data = []\n",
    "    sorted_pred_y_data = []\n",
    "    for iBin in range(1,nBins+1):\n",
    "        sorted_true_y_data.append(y_test[bin_means_true[2] == iBin, i])\n",
    "        sorted_pred_y_data.append(predictedY[bin_means_pred[2] == iBin,i])\n",
    "    \n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax = plt.subplot(212)\n",
    "\n",
    "    bin_pos = np.array([-2,-1]) # (because this makes it work)\n",
    "    x_label_centers = []\n",
    "    for iBin in range(nBins):\n",
    "        # Every boxplot adds 2 boxes, one from the true data and one from the predicted data\n",
    "        bin_pos += 3 \n",
    "        plt.boxplot([sorted_true_y_data[iBin], sorted_pred_y_data[iBin]] , positions = bin_pos, widths = 0.9)\n",
    "        x_label_centers.append(np.mean(bin_pos))\n",
    "    \n",
    "    plt.ylabel('%s %s' % (feat, unit_dict[feat]), fontsize=15)\n",
    "    plt.xlabel('True Halo mass log($M_{G}/M_{S}$)', fontsize=15)\n",
    "    ax.set_xlim(left=x_label_centers[0]-2, right=x_label_centers[-1]+2)\n",
    "    #xlim(0,bin_pos[1] + 1)\n",
    "    plt.xticks(x_label_centers, bin_centers) TODO fixa siffrorna\n",
    "    plt.text(12,7,'Left: true data. Right: predicted data.', fontsize=20)\n",
    "    \n",
    "    if feat == 'SFR':\n",
    "        ax.axhline(y=0, linestyle='--')\n",
    "    \n",
    "    #plt.title('nIterations: %d, training set size: %d, test mse score: %.2e\\n' % (nIterations, \n",
    "    #    train_size, testScore) + \n",
    "    #    '%d input feature(s): [%s]\\n%d output feature(s): [%s]\\n%d test data points (test) shown' % (\n",
    "    #    len(input_features), ', '.join(input_features), len(output_features), ', '.join(output_features),\n",
    "    #    test_size), y=1.03, fontsize=20)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    if save_figs:\n",
    "        fig.savefig(fig_dir+'pso_output_boxplot_%d_from_' % (i+1)+'_and_'.join(input_features)+'_to_'+\n",
    "            '_and_'.join(output_features)+'_with_'+param_string+'.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for loss\n",
    "%matplotlib inline\n",
    "fig = plt.figure(5, figsize=(8,8))\n",
    "plt.plot(trainingScoreHistory, 'b')\n",
    "plt.plot(validationScoreHistory, 'r')\n",
    "plt.yscale('log')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
