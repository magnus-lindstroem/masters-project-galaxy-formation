{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "from os.path import expanduser\n",
    "home_dir = expanduser(\"~\")\n",
    "module_path = home_dir + '/code/modules/'\n",
    "fig_dir = 'figures/'\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "import time\n",
    "import datetime\n",
    "import importlib\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data_processing\n",
    "%aimport plotting\n",
    "# %aimport pso\n",
    "%aimport pso_parallel_training_queue\n",
    "from data_processing import *\n",
    "from plotting import *\n",
    "# from pso import *\n",
    "from pso_parallel_training_queue import *\n",
    "\n",
    "np.random.seed(999)\n",
    "random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General parameters\n",
    "total_set_size = 2.9e5 # how many examples will be used for training+validation+testing\n",
    "train_size = 2e5\n",
    "val_size = .5e5\n",
    "test_size = .4e5\n",
    "input_features = ['Halo_mass', 'Halo_mass_peak', 'Scale_peak_mass', 'Scale_half_mass', 'Halo_growth_rate']#, 'Redshift']\n",
    "output_features = ['Stellar_mass', 'SFR']\n",
    "redshifts = [0]#,.1,.2,.5,1,2,3,4,6,8]\n",
    "same_n_points_per_redshift = False # if using the smf in the objective function, must be false!\n",
    "outputs_to_weigh = ['Stellar_mass']\n",
    "weigh_by_redshift = True\n",
    "\n",
    "reinforcement_learning = True\n",
    "real_observations = False\n",
    "\n",
    "verbatim = True\n",
    "\n",
    "network_name = '2018-07-31'\n",
    "\n",
    "### Network parameters\n",
    "nr_hidden_layers = 4\n",
    "activation_function = 'tanh'\n",
    "output_activation = {'SFR': None, 'Stellar_mass': None}\n",
    "nr_neurons_per_layer = 4\n",
    "regularisation_strength = 1e-2\n",
    "std_penalty = False\n",
    "norm = {'input': 'zero_mean_unit_std',\n",
    "        'output': 'zero_mean_unit_std'} # 'none',   'zero_mean_unit_std',   'zero_to_one'\n",
    "\n",
    "### PSO parameters\n",
    "nr_processes = 30\n",
    "nr_iterations = 1000\n",
    "x_min = -10\n",
    "x_max = 10\n",
    "alpha = 1\n",
    "delta_t = 1\n",
    "c1 = 2\n",
    "c2 = 2\n",
    "inertia_weight_start = 1.4\n",
    "inertia_weight_min = 0.1\n",
    "exploration_fraction = 0.8            # start making sure that the network did not converge to a local minimum\n",
    "min_std_tol = 0.01                # minimum allowed std for any parameter\n",
    "pso_param_dict = {\n",
    "    'nr_particles': 3 * nr_processes,\n",
    "    'patience': 1000,\n",
    "    'patience_parameter': 'train',\n",
    "    'restart_check_interval': 200\n",
    "}\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the selected galaxyfile\n",
    "galaxies, data_keys, unit_dict = load_galfiles(redshifts=redshifts, equal_numbers=same_n_points_per_redshift)\n",
    "    \n",
    "# prepare the training data\n",
    "training_data_dict = divide_train_data(galaxies, data_keys, input_features, output_features, redshifts, weigh_by_redshift, outputs_to_weigh,\n",
    "                                       int(total_set_size), train_size=int(train_size), val_size=int(val_size), test_size=int(test_size), pso=True)\n",
    "training_data_dict = normalise_data(training_data_dict, norm, pso=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:40:04  Iteration    0, particle  0, new swarm best. Train: 4.476e+02, Val: 3.398e+06\n",
      "10:40:06  Iteration    0, particle  3, new swarm best. Train: 1.227e+02, Val: 2.690e+05\n",
      "10:40:08  Iteration    0, particle 11, new swarm best. Train: 1.111e+02, Val: 1.729e+07\n",
      "10:40:10  Iteration    0, particle 18, new swarm best. Train: 1.003e+02, Val: 4.434e+05\n",
      "10:40:12  Iteration    0, particle 22, new swarm best. Train: 4.962e+01, Val: 1.043e+06\n",
      "10:40:14  Iteration    0, particle 72, new swarm best. Train: 3.022e+01, Val: 1.451e+07\n",
      "10:40:37  Iteration    1, particle  5, new swarm best. Train: 2.950e+01, Val: 3.261e+01\n",
      "10:40:39  Iteration    1, particle 21, new swarm best. Train: 2.832e+01, Val: 2.229e+06\n",
      "10:40:41  Iteration    1, particle 35, new swarm best. Train: 2.307e+01, Val: 4.830e+05\n",
      "10:40:43  Iteration    1, particle 77, new swarm best. Train: 1.626e+01, Val: 1.684e+01\n",
      "10:41:27  Iteration    3, particle 82, new swarm best. Train: 9.337e+00, Val: 9.519e+00\n",
      "10:42:10  Iteration    5, particle 17, new swarm best. Train: 7.967e+00, Val: 8.008e+00\n",
      "10:42:32  Iteration    6, particle 22, new swarm best. Train: 7.138e+00, Val: 7.172e+00\n",
      "10:42:34  Iteration    6, particle 84, new swarm best. Train: 7.022e+00, Val: 6.997e+00\n",
      "10:43:18  Iteration    8, particle 42, new swarm best. Train: 6.585e+00, Val: 7.062e+00\n",
      "10:43:20  Iteration    8, particle 82, new swarm best. Train: 6.538e+00, Val: 6.510e+00\n",
      "10:43:43  Iteration    9, particle 74, new swarm best. Train: 5.900e+00, Val: 6.046e+00\n",
      "10:45:28  Iteration   14, particle  1, new swarm best. Train: 5.833e+00, Val: 5.917e+00\n",
      "10:46:11  Iteration   16, particle 81, new swarm best. Train: 5.625e+00, Val: 5.581e+00\n",
      "10:46:33  Iteration   17, particle 20, new swarm best. Train: 5.419e+00, Val: 5.248e+00\n",
      "10:48:18  Iteration   22, particle 48, new swarm best. Train: 5.419e+00, Val: 5.432e+00\n",
      "10:48:20  Iteration   22, particle 68, new swarm best. Train: 5.299e+00, Val: 5.340e+00\n",
      "10:57:18  Iteration   48, particle 33, new swarm best. Train: 5.246e+00, Val: 5.461e+00\n",
      "10:57:41  Iteration   49, particle 81, new swarm best. Train: 4.460e+00, Val: 4.425e+00\n",
      "10:58:45  Iteration   52, particle 54, new swarm best. Train: 4.185e+00, Val: 4.150e+00\n",
      "11:00:10  Iteration   56, particle 68, new swarm best. Train: 3.949e+00, Val: 3.963e+00\n",
      "11:02:15  Iteration   62, particle 76, new swarm best. Train: 3.922e+00, Val: 3.892e+00\n",
      "11:05:22  Iteration   71, particle 47, new swarm best. Train: 3.566e+00, Val: 3.631e+00\n",
      "11:05:44  Iteration   72, particle 86, new swarm best. Train: 3.555e+00, Val: 3.580e+00\n",
      "11:36:38  Iteration  162, particle 17, new swarm best. Train: 3.492e+00, Val: 3.547e+00\n",
      "\n",
      "11:49:18, Iteration 200\n",
      "\n",
      "11:50:21  Iteration  202, particle 18, new swarm best. Train: 3.492e+00, Val: 3.520e+00\n",
      "11:52:06  Iteration  207, particle 51, new swarm best. Train: 3.424e+00, Val: 3.463e+00\n",
      "11:59:21  Iteration  228, particle 41, new swarm best. Train: 3.419e+00, Val: 3.499e+00\n",
      "12:02:50  Iteration  238, particle 43, new swarm best. Train: 3.411e+00, Val: 3.420e+00\n",
      "12:14:11  Iteration  271, particle 68, new swarm best. Train: 3.406e+00, Val: 3.425e+00\n",
      "12:17:38  Iteration  281, particle 80, new swarm best. Train: 3.312e+00, Val: 3.426e+00\n",
      "12:22:07  Iteration  294, particle 11, new swarm best. Train: 3.308e+00, Val: 3.388e+00\n",
      "12:23:51  Iteration  299, particle 29, new swarm best. Train: 3.281e+00, Val: 3.433e+00\n",
      "12:31:46  Iteration  322, particle 29, new swarm best. Train: 3.154e+00, Val: 3.178e+00\n",
      "12:44:48  Iteration  360, particle 76, new swarm best. Train: 2.927e+00, Val: 2.901e+00\n",
      "\n",
      "12:58:08, Iteration 400\n",
      "\n",
      "13:00:34  Iteration  406, particle 24, new swarm best. Train: 2.911e+00, Val: 2.942e+00\n",
      "13:18:25  Iteration  458, particle 17, new swarm best. Train: 2.839e+00, Val: 2.778e+00\n",
      "13:19:50  Iteration  462, particle  9, new swarm best. Train: 2.770e+00, Val: 2.725e+00\n",
      "\n",
      "14:06:38, Iteration 600\n",
      "\n",
      "14:24:44  Iteration  652, particle 53, new swarm best. Train: 2.642e+00, Val: 2.707e+00\n",
      "14:47:57  Iteration  720, particle 83, new swarm best. Train: 2.617e+00, Val: 2.573e+00\n",
      "14:58:16  Iteration  750, particle 44, new swarm best. Train: 2.529e+00, Val: 2.474e+00\n"
     ]
    }
   ],
   "source": [
    "network = Feed_Forward_Neural_Network(nr_hidden_layers, nr_neurons_per_layer, input_features, output_features, \n",
    "                                      activation_function, output_activation, regularisation_strength, network_name)\n",
    "network.setup_pso(pso_param_dict, reinf_learning=reinforcement_learning, real_observations=real_observations, nr_processes=nr_processes)\n",
    "start = time.time()\n",
    "network.train_pso(nr_iterations, training_data_dict, std_penalty=std_penalty, verbatim=verbatim)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set plot variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard plots\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('trained_networks/best_model.h5')\n",
    "training_data_dict = pickle.load(open('trained_networks/best_model_training_data_dict.p', 'rb'))\n",
    "\n",
    "mode = 'test' # 'train', 'val, 'test'\n",
    "\n",
    "predicted_points = predict_points(model, training_data_dict, mode = mode, original_units=False)\n",
    "title = 'Inputs: {}\\n{:.1e} train points, {}'.format(', '.join(input_features), train_size, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get reinforcement learning plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig73 = get_ssfr_plot(model, training_data_dict, unit_dict, galaxies=None, title=None, data_type=mode)\n",
    "fig55 = get_smf_plot(model, training_data_dict, unit_dict, galaxies=None, title=None, data_type=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig73.savefig(fig_dir + 'ssfr_plot_with_smf+ssfr_loss_func_6x6_1k_iters_Z00.png', bbox_inches = 'tight')\n",
    "fig55.savefig(fig_dir + 'smf_plot_with_smf+ssfr_loss_func_6x6_1k_iters_Z00.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get standard pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = get_pred_vs_real_scatterplot(model, training_data_dict, unit_dict, data_keys, 'Stellar_mass', pso=True, title=title, data_type=mode,\n",
    "                                   predicted_points = predicted_points, galaxies=galaxies)\n",
    "\n",
    "fig2 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, pso=True, predicted_feat = 'Stellar_mass', \n",
    "                                binning_feat = 'Halo_mass', title=title, data_type=mode,\n",
    "                                predicted_points = predicted_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = get_halo_stellar_mass_plots(model, training_data_dict, unit_dict, no_true_plots=True, title=title, y_max = None, y_min = None,\n",
    "                                    x_min = None, x_max = None, data_type=mode, predicted_points = predicted_points)\n",
    "\n",
    "fig4 = get_stellar_mass_sfr_plots(model, training_data_dict, unit_dict, no_true_plots=True, title=title, y_max = None, y_min = None,\n",
    "                                    x_min = None, x_max = None, data_type=mode, predicted_points = predicted_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3.savefig(fig_dir + 'halo_stellar_mass_plot_with_smf+ssfr_loss_func_6x6_1k_iters_Z00.png', bbox_inches = 'tight')\n",
    "fig4.savefig(fig_dir + 'stellar_mass_sfr_plot_with_smf+ssfr_loss_func_6x6_1k_iters_Z00.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig5 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, pso=True, predicted_feat = 'SFR', \n",
    "                                binning_feat = 'Stellar_mass', title=title, data_type=mode,\n",
    "                                predicted_points = predicted_points)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6 = get_real_vs_pred_same_fig(model, training_data_dict, unit_dict, x_axis_feature='Halo_mass', \n",
    "                                 y_axis_feature = 'Stellar_mass', pso=True, title=title, data_type=mode, marker_size=20, predicted_points=predicted_points,\n",
    "                                 y_min=None, y_max=None, x_min=None, x_max=None)\n",
    "# fig7 = get_real_vs_pred_same_fig(model, training_data_dict, unit_dict, x_axis_feature='Stellar_mass', \n",
    "#                                  y_axis_feature = 'SFR', pso=True, title=title, data_type=mode, marker_size=20,\n",
    "#                                  y_min=None, y_max=None, x_min=None, x_max=None)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig6.savefig(fig_dir + 'proof_of_concept_3x3_net_one_output_no_weighing.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mode = 'train'\n",
    "network.pso_swarm.set_best_weights('train')\n",
    "norm_score = network.pso_swarm.evaluate_model(mode)\n",
    "tot_score = norm_score\n",
    "model = network.model\n",
    "title = 'Inputs: %s\\ntest mse %.3e, %s data' % (', '.join(input_features), tot_score, mode)\n",
    "\n",
    "fig1 = get_pred_vs_real_scatterplot(model, training_data_dict, unit_dict, data_keys, 'SFR', title=title, mode=mode)\n",
    "fig2 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, predicted_feat = 'Stellar_mass', \n",
    "                                binning_feat = 'Halo_mass', title=title, mode=mode)\n",
    "fig3 = get_scatter_comparison_plots(model, training_data_dict, unit_dict, x_axis_feature = 'Halo_mass', \n",
    "                                    y_axis_feature = 'Stellar_mass', title=title, y_max = None, y_min = None,\n",
    "                                    x_min = None, x_max = None, mode=mode)\n",
    "fig4 = get_real_vs_pred_boxplot(model, training_data_dict, unit_dict, data_keys, 'SFR', \n",
    "                                binning_feat = 'Stellar_mass', title=title, mode=mode)\n",
    "fig5 = get_scatter_comparison_plots(model, training_data_dict, unit_dict, x_axis_feature = 'Halo_mass', \n",
    "                                    y_axis_feature = 'SFR', title=title, y_max = 10, y_min = None,\n",
    "                                    x_min = None, x_max = None, mode=mode)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nBins = 8\n",
    "bin_edges = np.linspace(halo_min_mass, halo_max_mass, nBins+1)\n",
    "\n",
    "predictedY = model.predict(x_test)\n",
    "\n",
    "for i, feat in enumerate(output_features):\n",
    "    \n",
    "    \n",
    "    ### Plot 1\n",
    "    fig = plt.figure(figsize=(16,16))\n",
    "    ax = plt.subplot(211)\n",
    "    plt.plot(y_test[:,i], y_test[:,i], 'k.')\n",
    "    plt.plot(predictedY[:,i], y_test[:,i], 'g.')\n",
    "    plt.ylabel('True %s %s' % (feat, unit_dict[feat]), fontsize=15)\n",
    "    plt.xlabel('Predicted %s %s' % (feat, unit_dict[feat]), fontsize=15)\n",
    "    plt.legend(['Ideal result', 'predicted ' + feat], loc='upper center')\n",
    "    plt.title('nIterations: %d, training set size: %d, test mse score: %.2e\\n' % (nIterations, \n",
    "        train_size, testScore) + \n",
    "        '%d input feature(s): [%s]\\n%d output feature(s): [%s]\\n%d test data points (test) shown' % (\n",
    "        len(input_features), ', '.join(input_features), len(output_features), ', '.join(output_features),\n",
    "        test_size), y=1.03, fontsize=20)\n",
    "    plt.show\n",
    "        \n",
    "    if save_figs:\n",
    "        fig.savefig(fig_dir+'pso_output_scatter_%d_plot_from_' % (i+1)+'_and_'.join(input_features)+'_to_'+\n",
    "            '_and_'.join(output_features)+'_with_'+param_string+'.png', bbox_inches = 'tight')\n",
    "    \n",
    "    ### Plot 2 - boxplot\n",
    "    \n",
    "    # bin_means contain (0: mean of the binned values, 1: bin edges, 2: numbers pointing each example to a bin)\n",
    "    bin_means_true = stats.binned_statistic(x_test[:,i], y_test[:,i], bins=bin_edges)\n",
    "    bin_means_pred = stats.binned_statistic(x_test[:,i], predictedY[:,i].flatten(), bins=bin_edges)\n",
    "    bin_centers = []\n",
    "    for iBin in range(nBins):\n",
    "        bin_centers.append((bin_means_true[1][iBin] + bin_means_true[1][iBin+1]) / 2)\n",
    "    sorted_true_y_data = []\n",
    "    sorted_pred_y_data = []\n",
    "    for iBin in range(1,nBins+1):\n",
    "        sorted_true_y_data.append(y_test[bin_means_true[2] == iBin, i])\n",
    "        sorted_pred_y_data.append(predictedY[bin_means_pred[2] == iBin,i])\n",
    "    \n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax = plt.subplot(212)\n",
    "\n",
    "    bin_pos = np.array([-2,-1]) # (because this makes it work)\n",
    "    x_label_centers = []\n",
    "    for iBin in range(nBins):\n",
    "        # Every boxplot adds 2 boxes, one from the true data and one from the predicted data\n",
    "        bin_pos += 3 \n",
    "        plt.boxplot([sorted_true_y_data[iBin], sorted_pred_y_data[iBin]] , positions = bin_pos, widths = 0.9)\n",
    "        x_label_centers.append(np.mean(bin_pos))\n",
    "    \n",
    "    plt.ylabel('%s %s' % (feat, unit_dict[feat]), fontsize=15)\n",
    "    plt.xlabel('True Halo mass log($M_{G}/M_{S}$)', fontsize=15)\n",
    "    ax.set_xlim(left=x_label_centers[0]-2, right=x_label_centers[-1]+2)\n",
    "    #xlim(0,bin_pos[1] + 1)\n",
    "    plt.xticks(x_label_centers, bin_centers) TODO fixa siffrorna\n",
    "    plt.text(12,7,'Left: true data. Right: predicted data.', fontsize=20)\n",
    "    \n",
    "    if feat == 'SFR':\n",
    "        ax.axhline(y=0, linestyle='--')\n",
    "    \n",
    "    #plt.title('nIterations: %d, training set size: %d, test mse score: %.2e\\n' % (nIterations, \n",
    "    #    train_size, testScore) + \n",
    "    #    '%d input feature(s): [%s]\\n%d output feature(s): [%s]\\n%d test data points (test) shown' % (\n",
    "    #    len(input_features), ', '.join(input_features), len(output_features), ', '.join(output_features),\n",
    "    #    test_size), y=1.03, fontsize=20)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    if save_figs:\n",
    "        fig.savefig(fig_dir+'pso_output_boxplot_%d_from_' % (i+1)+'_and_'.join(input_features)+'_to_'+\n",
    "            '_and_'.join(output_features)+'_with_'+param_string+'.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for loss\n",
    "%matplotlib inline\n",
    "fig = plt.figure(5, figsize=(8,8))\n",
    "plt.plot(trainingScoreHistory, 'b')\n",
    "plt.plot(validationScoreHistory, 'r')\n",
    "plt.yscale('log')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
