{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import expanduser\n",
    "home_dir = expanduser(\"~\")\n",
    "module_path = home_dir + '/code/modules/'\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "import time\n",
    "import datetime\n",
    "import importlib\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "import model_management\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data_processing\n",
    "%aimport plotting\n",
    "%aimport keras_objects\n",
    "%aimport pso\n",
    "from data_processing import *\n",
    "from plotting import *\n",
    "from keras_objects import *\n",
    "from pso import *\n",
    "\n",
    "np.random.seed(999)\n",
    "random.seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General parameters\n",
    "run_on_cpu = False\n",
    "total_set_size = 3000 # how many examples will be used for training+validation+testing\n",
    "train_size = 1000\n",
    "val_size = 1000\n",
    "test_size = 1000\n",
    "input_features = ['Halo_mass', 'Halo_mass_peak', 'Type', 'Concentration']\n",
    "output_features = ['Stellar_mass', 'SFR']\n",
    "nr_iters_before_restart_check = 60 # start making sure that the network did not converge to a local minimum\n",
    "min_std_tol = 0.01 # minimum allowed std for any parameter\n",
    "plot_threeD = 0\n",
    "save_figs = 0\n",
    "fig_dir = 'figures/'\n",
    "\n",
    "### Network parameters\n",
    "nr_hidden_layers = 10\n",
    "activationFunction = 'tanh'\n",
    "nr_neurons_per_layer = 10\n",
    "loss_function = 'halo_mass_weighted_loss'\n",
    "\n",
    "### PSO parameters\n",
    "nIterations = 1000\n",
    "nParticles = 40\n",
    "xMin = -10\n",
    "xMax = 10\n",
    "alpha = 1\n",
    "deltaT = 1\n",
    "c1 = 2\n",
    "c2 = 2\n",
    "inertiaWeightStart = 1.4\n",
    "inertiaWeightMin = 0.3\n",
    "explorationFraction = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_on_cpu:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set name ending with parameters for figures to be saved\n",
    "param_string = 'nLayers_%d_nNeurons_%d_actFun_%s_nTrainSamples_%d_nIterations_%d_' % (\n",
    "    nr_hidden_layers, nr_neurons_per_layer, activationFunction, train_size, nIterations)\n",
    "print(param_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the selected galaxyfile\n",
    "galaxies, data_keys, unit_dict = load_galfile()\n",
    "    \n",
    "# prepare the training data\n",
    "training_data_dict = divide_train_data(galaxies, data_keys, input_features, output_features, \n",
    "                                       int(total_set_size), int(train_size), int(val_size), int(test_size))\n",
    "galaxies = None\n",
    "training_data_dict = normalise_data(training_data_dict, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_pos', 'Y_pos', 'Z_pos', 'X_vel', 'Y_vel', 'Z_vel', 'Halo_mass', 'Stellar_mass', 'SFR', 'Intra_cluster_mass', 'Halo_mass_peak', 'Stellar_mass_obs', 'SFR_obs', 'Halo_radius', 'Concentration', 'Halo_spin', 'Scale_peak_mass', 'Scale_half_mass', 'Scale_last_MajM', 'Type']\n",
      "(594946, 20)\n",
      "(306925, 20)\n",
      "[11.06128  10.74806  10.517851 11.935673 11.820144 11.564987 10.759135\n",
      " 10.828308 10.803138 10.55098 ]\n"
     ]
    }
   ],
   "source": [
    "### OLD SHITTT DONT USE\n",
    "### OLD SHITTT DONT USE\n",
    "### OLD SHITTT DONT USE\n",
    "### OLD SHITTT DONT USE\n",
    "### OLD SHITTT DONT USE\n",
    "### OLD SHITTT DONT USE\n",
    "### OLD SHITTT DONT USE\n",
    "### OLD SHITTT DONT USE\n",
    "galfile = pd.read_hdf('/scratch/data/galcats/P200/galaxies.Z01.h5')\n",
    "galaxies = galfile.as_matrix()\n",
    "gal_header = galfile.keys().tolist()\n",
    "print(gal_header)\n",
    "\n",
    "### Remove data points with halo mass below 10.5\n",
    "print(np.shape(galaxies))\n",
    "galaxies = galaxies[galaxies[:,6] > 10.5, :]\n",
    "print(np.shape(galaxies))\n",
    "print(galaxies[:10,6])\n",
    "\n",
    "halo_min_mass = np.min(galaxies[:, 6])\n",
    "halo_max_mass = np.max(galaxies[:, 6])\n",
    "\n",
    "### Create the different data sets that will be used\n",
    "n_data_points = galaxies.shape[0]\n",
    "subset_indices = np.random.choice(n_data_points, total_set_size, replace=False)\n",
    "train_indices = subset_indices[: train_size]\n",
    "val_indices = subset_indices[train_size : train_size+val_size]\n",
    "test_indices = subset_indices[train_size+val_size :]\n",
    "\n",
    "x_train = np.zeros((len(train_indices), len(input_features)))\n",
    "x_val = np.zeros((len(val_indices), len(input_features)))\n",
    "x_test = np.zeros((len(test_indices), len(input_features)))\n",
    "y_train = np.zeros((len(train_indices), len(output_features)))\n",
    "y_val = np.zeros((len(val_indices), len(output_features)))\n",
    "y_test = np.zeros((len(test_indices), len(output_features)))\n",
    "\n",
    "for i in range(len(input_features)):\n",
    "    x_train[:,i] = galaxies[train_indices, data_dict[input_features[i]]]\n",
    "    x_val[:,i] = galaxies[val_indices, data_dict[input_features[i]]]\n",
    "    x_test[:,i] = galaxies[test_indices, data_dict[input_features[i]]]\n",
    "    \n",
    "for i in range(len(output_features)):\n",
    "    y_train[:,i] = galaxies[train_indices, data_dict[output_features[i]]]\n",
    "    y_val[:,i] = galaxies[val_indices, data_dict[output_features[i]]]\n",
    "    y_test[:,i] = galaxies[test_indices, data_dict[output_features[i]]]\n",
    "\n",
    "### If you want to preprocess the data\n",
    "\n",
    "for i in range(np.size(x_train, 1)):\n",
    "    x_data_means = np.mean(x_train, 0)\n",
    "    x_data_stds = np.std(x_train, 0)\n",
    "\n",
    "    x_train_norm = (x_train - x_data_means) / x_data_stds\n",
    "    x_val_norm = (x_val - x_data_means) / x_data_stds\n",
    "    x_test_norm = (x_test - x_data_means) / x_data_stds\n",
    "\n",
    "for i in range(np.size(y_train, 1)):\n",
    "    y_data_means = np.mean(y_train, 0)\n",
    "    y_data_stds = np.std(y_train, 0)\n",
    "\n",
    "    y_train_norm = (y_train - y_data_means) / y_data_stds\n",
    "    y_val_norm = (y_val - y_data_means) / y_data_stds\n",
    "    y_test_norm = (y_test - y_data_means) / y_data_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00493404 -0.02780973]\n",
      "[1.03360238 0.88024908]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(y_test_norm, 0))\n",
    "print(np.std(y_test_norm, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halo_mass : min: 1.05e+01, max: 1.41e+01.\n",
      "Halo_mass_peak : min: 1.05e+01, max: 1.41e+01.\n",
      "Type : min: 0.00e+00, max: 2.00e+00.\n",
      "Concentration : min: 1.01e+00, max: 8.28e+02.\n",
      "Stellar_mass : min: 7.00e+00, max: 1.16e+01.\n",
      "SFR : min: 0.00e+00, max: 8.82e+00.\n"
     ]
    }
   ],
   "source": [
    "### Get a feel for the data\n",
    "for i in range(len(input_features)):\n",
    "    print(input_features[i],': min: %.2e, max: %.2e.' % (np.min(x_train[:,i]), np.max(x_train[:,i])))\n",
    "for i in range(len(output_features)):\n",
    "    print(output_features[i],': min: %.2e, max: %.2e.' % (np.min(y_train[:,i]), np.max(y_train[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Visualisation for when we have 2 input features\n",
    "%matplotlib notebook\n",
    "input_feat_1 = 0\n",
    "input_feat_2 = 1\n",
    "output_feat = 1\n",
    "\n",
    "fig = plt.figure(1, figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x_train_norm[:500,input_feat_1], x_train_norm[:500,input_feat_2], \n",
    "           y_train_norm[:500,output_feat])\n",
    "ax.set_xlabel('%s log($M_{H}/M_{S}$)' % (input_features[input_feat_1]))\n",
    "ax.set_ylabel('%s log($M_{H}/M_{S}$)' % (input_features[input_feat_2]))\n",
    "ax.set_zlabel('%s log($M_{G}/M_{S}$)' % (output_features[output_feat]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a new network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Feed_Forward_Neural_Network(nr_hidden_layers, nr_neurons_per_layer, input_features, output_features, \n",
    "                                      activationFunction)\n",
    "network.pso_setup({'inertiaWeightMin': 0.1})\n",
    "network.pso_train(nIterations, training_data_dict, loss_function, speed_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, particle 0, new swarm best. Train: 482.630, Val: 482.388\n",
      "Iteration 0, particle 1, new swarm best. Train: 199.518, Val: 200.337\n",
      "Iteration 0, particle 2, new swarm best. Train: 181.035, Val: 167.628\n",
      "Iteration 0, particle 15, new swarm best. Train: 107.157, Val: 111.159\n",
      "Iteration 2, particle 1, new swarm best. Train: 83.046, Val: 79.279\n",
      "Iteration 2, particle 38, new swarm best. Train: 75.747, Val: 77.890\n",
      "Iteration 3, particle 22, new swarm best. Train: 75.695, Val: 74.420\n",
      "Iteration 3, particle 28, new swarm best. Train: 44.008, Val: 45.939\n",
      "Iteration 5, particle 28, new swarm best. Train: 41.107, Val: 39.798\n",
      "Iteration 6, particle 10, new swarm best. Train: 37.852, Val: 38.062\n",
      "Iteration 6, particle 33, new swarm best. Train: 34.302, Val: 36.214\n",
      "Iteration 8, particle 12, new swarm best. Train: 25.685, Val: 25.408\n",
      "Iteration 9, particle 20, new swarm best. Train: 17.032, Val: 18.317\n",
      "Iteration 9, particle 22, new swarm best. Train: 16.049, Val: 16.624\n",
      "Iteration 9, particle 29, new swarm best. Train: 14.862, Val: 15.911\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nr_iters_before_restart_check' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e7a41ebae7a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                                       activationFunction)\n\u001b[1;32m      3\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpso_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'inertiaWeightMin'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpso_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnIterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeed_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/modules/pso.py\u001b[0m in \u001b[0;36mpso_train\u001b[0;34m(self, nr_iterations, x_train, y_train, x_val, y_val, speed_check)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpso_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnr_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeed_check\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpso_swarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnr_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeed_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/modules/pso.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(self, nr_iterations, x_train, y_train, x_val, y_val, speed_check)\u001b[0m\n\u001b[1;32m    119\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                         \u001b[0;31m# see if network has run into a local minima\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlastTimeSwarmBest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnr_iters_before_restart_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nr_iters_before_restart_check' is not defined"
     ]
    }
   ],
   "source": [
    "### OLD SHITTT DONT USE\n",
    "### OLD SHITTT DONT USE\n",
    "### OLD SHITTT DONT USE\n",
    "### OLD SHITTT DONT USE\n",
    "### OLD SHITTT DONT USE\n",
    "### OLD SHITTT DONT USE\n",
    "network = Feed_Forward_Neural_Network(nr_hidden_layers, nr_neurons_per_layer, input_features, output_features, \n",
    "                                      activationFunction)\n",
    "network.pso_setup({'inertiaWeightMin': 0.1})\n",
    "network.pso_train(nIterations, x_train_norm, y_train_norm, x_val_norm, y_val_norm, data_dict, speed_check=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualisation of prediction strength for when we have 2 input features\n",
    "if plot_threeD and len(input_features) == 2:\n",
    "    predictedY = PredictFunc(bestWeightList, bestBiasList, model, 'test')\n",
    "    fig = plt.figure(2, figsize=(8,8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(x_test[:,0], x_test[:,1], \n",
    "               y_test[:,0], s=3)\n",
    "    ax.scatter(x_test[:,0], x_test[:,1], \n",
    "               predictedY, s=3)\n",
    "    ax.set_xlabel('%s log($M_{H}/M_{S}$)' % (input_features[0]))\n",
    "    ax.set_ylabel('%s log($M_{H}/M_{S}$)' % (input_features[1]))\n",
    "    ax.set_zlabel('%s log($M_{G}/M_{S}$)' % (output_features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nBins = 8\n",
    "bin_edges = np.linspace(halo_min_mass, halo_max_mass, nBins+1)\n",
    "\n",
    "predictedY = model.predict(x_test)\n",
    "\n",
    "for i, feat in enumerate(output_features):\n",
    "    \n",
    "    \n",
    "    ### Plot 1\n",
    "    fig = plt.figure(figsize=(16,16))\n",
    "    ax = plt.subplot(211)\n",
    "    plt.plot(y_test[:,i], y_test[:,i], 'k.')\n",
    "    plt.plot(predictedY[:,i], y_test[:,i], 'g.')\n",
    "    plt.ylabel('True %s %s' % (feat, unit_dict[feat]), fontsize=15)\n",
    "    plt.xlabel('Predicted %s %s' % (feat, unit_dict[feat]), fontsize=15)\n",
    "    plt.legend(['Ideal result', 'predicted ' + feat], loc='upper center')\n",
    "    plt.title('nIterations: %d, training set size: %d, test mse score: %.2e\\n' % (nIterations, \n",
    "        train_size, testScore) + \n",
    "        '%d input feature(s): [%s]\\n%d output feature(s): [%s]\\n%d test data points (test) shown' % (\n",
    "        len(input_features), ', '.join(input_features), len(output_features), ', '.join(output_features),\n",
    "        test_size), y=1.03, fontsize=20)\n",
    "    plt.show\n",
    "        \n",
    "    if save_figs:\n",
    "        fig.savefig(fig_dir+'pso_output_scatter_%d_plot_from_' % (i+1)+'_and_'.join(input_features)+'_to_'+\n",
    "            '_and_'.join(output_features)+'_with_'+param_string+'.png', bbox_inches = 'tight')\n",
    "    \n",
    "    ### Plot 2 - boxplot\n",
    "    \n",
    "    # bin_means contain (0: mean of the binned values, 1: bin edges, 2: numbers pointing each example to a bin)\n",
    "    bin_means_true = stats.binned_statistic(x_test[:,i], y_test[:,i], bins=bin_edges)\n",
    "    bin_means_pred = stats.binned_statistic(x_test[:,i], predictedY[:,i].flatten(), bins=bin_edges)\n",
    "    bin_centers = []\n",
    "    for iBin in range(nBins):\n",
    "        bin_centers.append((bin_means_true[1][iBin] + bin_means_true[1][iBin+1]) / 2)\n",
    "    sorted_true_y_data = []\n",
    "    sorted_pred_y_data = []\n",
    "    for iBin in range(1,nBins+1):\n",
    "        sorted_true_y_data.append(y_test[bin_means_true[2] == iBin, i])\n",
    "        sorted_pred_y_data.append(predictedY[bin_means_pred[2] == iBin,i])\n",
    "    \n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax = plt.subplot(212)\n",
    "\n",
    "    bin_pos = np.array([-2,-1]) # (because this makes it work)\n",
    "    x_label_centers = []\n",
    "    for iBin in range(nBins):\n",
    "        # Every boxplot adds 2 boxes, one from the true data and one from the predicted data\n",
    "        bin_pos += 3 \n",
    "        plt.boxplot([sorted_true_y_data[iBin], sorted_pred_y_data[iBin]] , positions = bin_pos, widths = 0.9)\n",
    "        x_label_centers.append(np.mean(bin_pos))\n",
    "    \n",
    "    plt.ylabel('%s %s' % (feat, unit_dict[feat]), fontsize=15)\n",
    "    plt.xlabel('True Halo mass log($M_{G}/M_{S}$)', fontsize=15)\n",
    "    ax.set_xlim(left=x_label_centers[0]-2, right=x_label_centers[-1]+2)\n",
    "    #xlim(0,bin_pos[1] + 1)\n",
    "    plt.xticks(x_label_centers, bin_centers) TODO fixa siffrorna\n",
    "    plt.text(12,7,'Left: true data. Right: predicted data.', fontsize=20)\n",
    "    \n",
    "    if feat == 'SFR':\n",
    "        ax.axhline(y=0, linestyle='--')\n",
    "    \n",
    "    #plt.title('nIterations: %d, training set size: %d, test mse score: %.2e\\n' % (nIterations, \n",
    "    #    train_size, testScore) + \n",
    "    #    '%d input feature(s): [%s]\\n%d output feature(s): [%s]\\n%d test data points (test) shown' % (\n",
    "    #    len(input_features), ', '.join(input_features), len(output_features), ', '.join(output_features),\n",
    "    #    test_size), y=1.03, fontsize=20)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    if save_figs:\n",
    "        fig.savefig(fig_dir+'pso_output_boxplot_%d_from_' % (i+1)+'_and_'.join(input_features)+'_to_'+\n",
    "            '_and_'.join(output_features)+'_with_'+param_string+'.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for loss\n",
    "%matplotlib inline\n",
    "fig = plt.figure(5, figsize=(8,8))\n",
    "plt.plot(trainingScoreHistory, 'b')\n",
    "plt.plot(validationScoreHistory, 'r')\n",
    "plt.yscale('log')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
