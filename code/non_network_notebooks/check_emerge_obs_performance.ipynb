{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "from os.path import expanduser\n",
    "home_dir = expanduser(\"~\")\n",
    "module_path = home_dir + '/code/modules/'\n",
    "models_path = home_dir + '/models/'\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "fig_dir = 'figures/'\n",
    "bp_network_dir = home_dir + '/trained_networks/backprop_trained/'\n",
    "import time\n",
    "import random\n",
    "from loading_datasets import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "from scipy.special import comb\n",
    "import multiprocessing as mp\n",
    "import datetime\n",
    "import codecs, json\n",
    "import corner\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data_processing\n",
    "%aimport multiprocessing_modules\n",
    "%aimport plotting\n",
    "%aimport model_setup\n",
    "from data_processing import *\n",
    "from observational_data_management import binned_loss, csfrd_loss, clustering_loss\n",
    "from multiprocessing_modules import train_net, init\n",
    "from plotting import *\n",
    "from model_setup import *\n",
    "\n",
    "np.random.seed(999)\n",
    "random.seed(999)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max resolvable stellar masses are, for redshifts 0.00, 0.10, 0.20, 0.50, 1.00, 2.00, 3.00, 4.00, 6.00, 8.00:  [11.917698348869193, 11.919560018029657, 11.919560018029657, 12.008884738658642, 11.950992202758789, 11.871992912521591, 11.946076673215574, 11.745095703480121, 10.917188149815923, 9.582553102113343]\n"
     ]
    }
   ],
   "source": [
    "# y_pred = data_processing.predict_points(model, training_data_dict, original_units=False, as_lists=False, data_type=data_type)\n",
    "            \n",
    "# sfr_index = training_data_dict['network_args']['output_features'].index('SFR')\n",
    "# stellar_mass_index = training_data_dict['network_args']['output_features'].index('Stellar_mass')\n",
    "\n",
    "tot_nr_points = 'all' # how many examples will be used for training+validation+testing, 'all' or a number\n",
    "train_frac = 1\n",
    "val_frac = 0\n",
    "test_frac = 0\n",
    "\n",
    "redshifts = [0,.1,.2,.5,1,2,3,4,6,8]\n",
    "same_n_points_per_redshift = False\n",
    "input_features = ['Halo_mass_peak', 'Scale_peak_mass', 'Halo_growth_rate', 'Halo_radius', 'Redshift']\n",
    "output_features = ['Stellar_mass', 'SFR']\n",
    "outputs_to_weigh = ['Stellar_mass']\n",
    "weigh_by_redshift = True\n",
    "\n",
    "norm = {'input': 'zero_mean_unit_std',\n",
    "        'output': 'none'} # 'none',   'zero_mean_unit_std',   'zero_to_one'\n",
    "\n",
    "network_args = {        \n",
    "    'nr_hidden_layers': 8,\n",
    "    'nr_neurons_per_lay': 8,\n",
    "    'input_features': input_features,\n",
    "    'output_features': output_features,\n",
    "    'activation_function': 'tanh', # 'tanh', 'leaky_relu'\n",
    "    'output_activation': {'SFR': None, 'Stellar_mass': None},\n",
    "    'reg_strength': 0\n",
    "}\n",
    "### Loss parameters\n",
    "stellar_mass_bin_width = 0.2 # concerns smf, fq, ssfr losses\n",
    "loss_dict = {\n",
    "    'fq_weight': 1,\n",
    "    'ssfr_weight': 1,\n",
    "    'smf_weight': 1, \n",
    "    'shm_weight': 2, # only available when using mock observations\n",
    "    'csfrd_weight': 1,\n",
    "    'clustering_weight': 1,\n",
    "    'nr_redshifts_per_eval': 'all', # a nr or the string 'all'\n",
    "    'stellar_mass_bins': np.arange(7, 12.5, stellar_mass_bin_width),\n",
    "    'stellar_mass_bin_width': stellar_mass_bin_width\n",
    "}\n",
    "\n",
    "# load the selected galaxyfile\n",
    "galaxies, data_keys = load_galfiles(redshifts=redshifts, equal_numbers=same_n_points_per_redshift)\n",
    "    \n",
    "# prepare the training data\n",
    "training_data_dict = divide_train_data(galaxies, data_keys, network_args, redshifts, outputs_to_weigh=outputs_to_weigh, \n",
    "                                       weigh_by_redshift=weigh_by_redshift, total_set_size=tot_nr_points, train_frac=train_frac, val_frac=val_frac, \n",
    "                                       test_frac=test_frac, real_observations=True, emerge_targets=True, loss_dict=loss_dict)\n",
    "training_data_dict = normalise_data(training_data_dict, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.04092176373937\n"
     ]
    }
   ],
   "source": [
    "predicted_sfr = np.power(10, training_data_dict['output_train_dict']['SFR'])\n",
    "\n",
    "predicted_stellar_mass_log = training_data_dict['output_train_dict']['Stellar_mass']\n",
    "predicted_stellar_mass = np.power(10, predicted_stellar_mass_log)\n",
    "\n",
    "try:\n",
    "    ssfr = np.divide(predicted_sfr, predicted_stellar_mass)\n",
    "except:\n",
    "    print(np.dtype(predicted_sfr[0]), np.dtype(predicted_stellar_mass[0]))\n",
    "    print('predicted_sfr: ',predicted_sfr)\n",
    "    print('predicted_stellar_mass: ', predicted_stellar_mass)\n",
    "    sys.exit('overflow error while dividing')\n",
    "\n",
    "try:\n",
    "    ssfr_log = np.log10(ssfr)\n",
    "except:\n",
    "    print(np.dtype(ssfr[0]))\n",
    "    print('ssfr: ',ssfr)\n",
    "    sys.exit('divide by zero error while taking log')\n",
    "    \n",
    "data_type = 'train'\n",
    "\n",
    "loss = 0\n",
    "\n",
    "############### mean SSFR ###############\n",
    "\n",
    "if loss_dict['ssfr_weight'] > 0:\n",
    "    loss_ssfr = \\\n",
    "        binned_loss(training_data_dict, predicted_stellar_mass_log, ssfr, 'ssfr', data_type, loss_dict, True) \n",
    "    loss += loss_dict['ssfr_weight'] * loss_ssfr\n",
    "\n",
    "############### SMF ###############  \n",
    "\n",
    "if loss_dict['smf_weight'] > 0:\n",
    "    loss_smf = \\\n",
    "        binned_loss(training_data_dict, predicted_stellar_mass_log, predicted_stellar_mass_log, 'smf', data_type, loss_dict,\n",
    "                    True)\n",
    "    loss += loss_dict['smf_weight'] * loss_smf\n",
    "\n",
    "############### FQ ###############\n",
    "\n",
    "if loss_dict['fq_weight'] > 0:\n",
    "    loss_fq = \\\n",
    "        binned_loss(training_data_dict, predicted_stellar_mass_log, ssfr_log, 'fq', data_type, loss_dict, True)\n",
    "    loss += loss_dict['fq_weight'] * loss_fq\n",
    "\n",
    "############### CSFRD ###############\n",
    "\n",
    "if loss_dict['csfrd_weight'] > 0:\n",
    "    loss_csfrd = csfrd_loss(\n",
    "        training_data_dict, predicted_sfr, loss_dict, data_type\n",
    "    )\n",
    "    loss += loss_dict['csfrd_weight'] * loss_csfrd\n",
    "\n",
    "############### Clustering ###############\n",
    "\n",
    "if loss_dict['clustering_weight'] > 0:\n",
    "    loss_clustering = clustering_loss(\n",
    "        training_data_dict, predicted_stellar_mass_log, loss_dict, data_type\n",
    "    )\n",
    "    loss += loss_dict['clustering_weight'] * loss_clustering\n",
    "\n",
    "loss /= (loss_dict['ssfr_weight'] + loss_dict['smf_weight'] + loss_dict['fq_weight'] + loss_dict['clustering_weight']\n",
    "         + loss_dict['csfrd_weight'])\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
