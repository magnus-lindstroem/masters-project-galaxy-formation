{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "import os\n",
    "from os.path import expanduser\n",
    "home_dir = expanduser(\"~\")\n",
    "module_path = home_dir + '/code/modules/'\n",
    "models_path = home_dir + '/models/'\n",
    "import sys\n",
    "sys.path.append(module_path)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import json\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport data_processing\n",
    "from data_processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct mock SMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_directory = '/home/magnus/data/galcats_nonzero_sfr_no_density_with_growth_rate_no_lastMajM/'\n",
    "destination_directory = '/home/magnus/data/mock_data/stellar_mass_functions/'\n",
    "\n",
    "redshifts = [0, .1, .2, .5, 1, 2, 3, 4, 6, 8]\n",
    "bin_width = .1\n",
    "error = .3\n",
    "\n",
    "for redshift in redshifts:\n",
    "\n",
    "    file_name = 'galaxies.Z{:02.0f}'.format(redshift*10)\n",
    "\n",
    "    galfile = pd.read_hdf(original_directory + file_name + '.h5')\n",
    "    galaxies = galfile.values\n",
    "    gal_header = galfile.keys().tolist()\n",
    "\n",
    "    data_keys = {}\n",
    "    for col_nr, key in enumerate(gal_header):\n",
    "        data_keys[key] = col_nr\n",
    "\n",
    "    # Remove the smaller haloes\n",
    "    galaxies = galaxies[galaxies[:,data_keys['Halo_mass']] > 10.5, :]\n",
    "\n",
    "  #  print(np.amax(galaxies[:, data_keys['Halo_mass']]))\n",
    "  #  print(np.amin(galaxies[:, data_keys['Halo_mass']]))\n",
    "\n",
    "    max_stellar_mass = np.amax(galaxies[:, data_keys['Stellar_mass']])\n",
    "    min_stellar_mass = np.amin(galaxies[:, data_keys['Stellar_mass']])\n",
    "    lower_bin_edge = np.floor(min_stellar_mass * 10)/10\n",
    "    upper_bin_edge = np.ceil(max_stellar_mass* 10)/10\n",
    "   # print(min_stellar_mass, max_stellar_mass)\n",
    "   # print(lower_bin_edge, upper_bin_edge)\n",
    "\n",
    "    bin_edges = np.arange(lower_bin_edge, upper_bin_edge + bin_width, bin_width)\n",
    "    n_bins = len(bin_edges)-1\n",
    "    bin_stats = stats.binned_statistic(galaxies[:, data_keys['Stellar_mass']], galaxies[:, data_keys['Stellar_mass']], \n",
    "                                       bins=bin_edges)\n",
    "\n",
    "    bin_counts = [np.sum(bin_stats[2] == i) for i in range(1, n_bins+1)]\n",
    "\n",
    "    bin_centers = [(bin_edges[i] + bin_edges[i+1])/2 for i in range(len(bin_edges)-1)]\n",
    "  #  print(bin_centers)\n",
    "\n",
    "    #plt.hist(galaxies[:, data_keys['Stellar_mass']], bins = bin_edges, density = False, label = 'Stellar_mass')\n",
    "  #  plt.scatter(bin_centers, bin_counts)\n",
    "\n",
    "  #  print(bin_counts)\n",
    "    bin_counts = [float('nan') if count == 0 else count for count in bin_counts]\n",
    "    bin_counts_arr = np.array(bin_counts, dtype=np.float)\n",
    "    bin_counts_per_mpc3 = bin_counts_arr / 200**3 / bin_width\n",
    "    bin_counts_per_mpc3[bin_counts_per_mpc3 > 0] = np.log10(bin_counts_per_mpc3[bin_counts_per_mpc3 > 0])\n",
    "  #  print(bin_counts_per_mpc3)\n",
    "\n",
    "    full_data_list = [[stell_mass, phi, error] for (stell_mass, phi) in zip(bin_centers, bin_counts_per_mpc3) \n",
    "                      if (not np.isnan(phi)) ]\n",
    "    full_data_list.insert(0, {'bin_widths': bin_width, 'bin_edges': bin_edges.tolist()})\n",
    "  #  print(full_data_list)\n",
    "\n",
    "    with open(destination_directory + file_name + '.json', 'w+') as f:\n",
    "        json.dump(full_data_list, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Try loading a data file\n",
    "file_name = 'galaxies.Z00'\n",
    "with open(destination_directory + file_name + '.json', 'r') as f:\n",
    "    test = json.load(f)\n",
    "f.close()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct mock SSFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_directory = '/home/magnus/data/galcats_nonzero_sfr_no_density_with_growth_rate_no_lastMajM/'\n",
    "destination_directory = '/home/magnus/data/mock_data/ssfr/'\n",
    "redshifts = [0, .1, .2, .5, 1, 2, 3, 4, 6, 8]\n",
    "\n",
    "for redshift in redshifts:\n",
    "\n",
    "    file_name = 'galaxies.Z{:02.0f}'.format(redshift*10)\n",
    "    \n",
    "    bin_width = .2\n",
    "    error = .3\n",
    "\n",
    "    galfile = pd.read_hdf(original_directory + file_name + '.h5')\n",
    "    galaxies = galfile.values\n",
    "    gal_header = galfile.keys().tolist()\n",
    "\n",
    "    data_keys = {}\n",
    "    for col_nr, key in enumerate(gal_header):\n",
    "        data_keys[key] = col_nr\n",
    "\n",
    "    # Remove the smaller haloes\n",
    "    galaxies = galaxies[galaxies[:,data_keys['Halo_mass']] > 10.5, :]\n",
    "\n",
    "    # print(np.amax(galaxies[:, data_keys['Halo_mass']]))\n",
    "    # print(np.amin(galaxies[:, data_keys['Halo_mass']]))\n",
    "\n",
    "    sfr_log = galaxies[:, data_keys['SFR']]\n",
    "    sfr = np.power(10, sfr_log)\n",
    "    # print(np.amax(sfr))\n",
    "    # print(np.amin(sfr))\n",
    "\n",
    "    stellar_mass_log = galaxies[:, data_keys['Stellar_mass']]\n",
    "    stellar_mass = np.power(10, stellar_mass_log)\n",
    "    # print('{:.3e}'.format(np.amax(stellar_mass)))\n",
    "    # print('{:.3e}'.format(np.amin(stellar_mass)))\n",
    "\n",
    "    ssfr = sfr / stellar_mass\n",
    "    ssfr_log = np.log10(ssfr)\n",
    "\n",
    "    max_stellar_mass = np.amax(stellar_mass_log)\n",
    "    min_stellar_mass = np.amin(stellar_mass_log)\n",
    "    lower_bin_edge = np.floor(min_stellar_mass * 10)/10\n",
    "    upper_bin_edge = np.ceil(max_stellar_mass* 10)/10\n",
    "    # print(min_stellar_mass, max_stellar_mass)\n",
    "    # print(lower_bin_edge, upper_bin_edge)\n",
    "    if (upper_bin_edge - lower_bin_edge) % bin_width > 1e-5 and (upper_bin_edge - lower_bin_edge) % bin_width < bin_width - 1e-5:\n",
    "    #     print((upper_bin_edge - lower_bin_edge) % bin_width)\n",
    "    #     print('hej')\n",
    "        upper_bin_edge += (upper_bin_edge - lower_bin_edge) % bin_width\n",
    "    # print(lower_bin_edge, upper_bin_edge)\n",
    "\n",
    "    bin_edges = np.arange(lower_bin_edge, upper_bin_edge + bin_width, bin_width)\n",
    "    n_bins = len(bin_edges)-1\n",
    "    bin_stats_means = stats.binned_statistic(stellar_mass_log, ssfr_log, bins=bin_edges, statistic='mean')\n",
    "    bin_stats_stds = stats.binned_statistic(stellar_mass_log, ssfr_log, bins=bin_edges, statistic=np.std)\n",
    "    bin_means = bin_stats_means[0]\n",
    "    bin_stds = bin_stats_stds[0]\n",
    "    # print(bin_means)\n",
    "    # print(bin_stds)\n",
    "\n",
    "    bin_centers = [(bin_edges[i] + bin_edges[i+1])/2 for i in range(len(bin_edges)-1)]\n",
    "    # print(bin_edges)\n",
    "    # print(bin_centers)\n",
    "\n",
    "    # plt.errorbar(bin_centers, bin_means, yerr=bin_stds, fmt = 'bo')\n",
    "\n",
    "    full_data_list = [[stell_mass, mean_ssfr_log, error] for (stell_mass, mean_ssfr_log) in zip(bin_centers, bin_means)]\n",
    "    full_data_list.insert(0, {'bin_widths': bin_width, 'bin_edges': bin_edges.tolist()})\n",
    "    # print(full_data_list)\n",
    "\n",
    "    with open(destination_directory + file_name + '.json', 'w+') as f:\n",
    "        json.dump(full_data_list, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct mock fraction of quenched galaxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_directory = '/home/magnus/data/galcats_nonzero_sfr_no_density_with_growth_rate_no_lastMajM/'\n",
    "destination_directory = '/home/magnus/data/mock_data/fq/'\n",
    "redshifts = [0, .1, .2, .5, 1, 2, 3, 4, 6, 8]\n",
    "\n",
    "np.seterr(invalid='raise')\n",
    "\n",
    "for i_red, redshift in enumerate(redshifts):\n",
    "    scale_factor = 1 / (1 + redshift)\n",
    "\n",
    "    h_0 = 67.81 / (3.09e19) # 1/s\n",
    "    h_0 = h_0 * 60 * 60 * 24 * 365 # 1/yr\n",
    "    h_r = h_0 * np.sqrt(1e-3*scale_factor**(-4) + 0.308*scale_factor**(-3) + 0*scale_factor**(-2) + 0.692)\n",
    "    ssfr_cutoff = 0.3*h_r\n",
    "    log_ssfr_cutoff = np.log10(ssfr_cutoff)\n",
    "\n",
    "    file_name = 'galaxies.Z{:02.0f}'.format(redshift*10)\n",
    "\n",
    "    bin_width = .25\n",
    "    error = .3\n",
    "\n",
    "    galfile = pd.read_hdf(original_directory + file_name + '.h5')\n",
    "    galaxies = galfile.values\n",
    "    gal_header = galfile.keys().tolist()\n",
    "\n",
    "    data_keys = {}\n",
    "    for col_nr, key in enumerate(gal_header):\n",
    "        data_keys[key] = col_nr\n",
    "\n",
    "    # Remove the smaller haloes\n",
    "    galaxies = galaxies[galaxies[:,data_keys['Halo_mass']] > 10.5, :]\n",
    "\n",
    "#     print(np.amax(galaxies[:, data_keys['Halo_mass']]))\n",
    "#     print(np.amin(galaxies[:, data_keys['Halo_mass']]))\n",
    "\n",
    "    sfr_log = galaxies[:, data_keys['SFR']]\n",
    "    sfr = np.power(10, sfr_log)\n",
    "    # print(np.amax(sfr))\n",
    "    # print(np.amin(sfr))\n",
    "\n",
    "    stellar_mass_log = galaxies[:, data_keys['Stellar_mass']]\n",
    "    stellar_mass = np.power(10, stellar_mass_log)\n",
    "    # print('{:.3e}'.format(np.amax(stellar_mass)))\n",
    "    # print('{:.3e}'.format(np.amin(stellar_mass)))\n",
    "\n",
    "    ssfr = sfr / stellar_mass\n",
    "\n",
    "    # print(np.min(ssfr), np.max(ssfr))\n",
    "    # print(h_r)\n",
    "\n",
    "    ssfr_log = np.log10(ssfr)\n",
    "\n",
    "    max_stellar_mass = np.amax(stellar_mass_log)\n",
    "    min_stellar_mass = np.amin(stellar_mass_log)\n",
    "    lower_bin_edge = np.floor(min_stellar_mass * 1/bin_width)*bin_width\n",
    "    upper_bin_edge = np.ceil(max_stellar_mass * 1/bin_width)*bin_width\n",
    "#     print(min_stellar_mass, max_stellar_mass)\n",
    "#     print(lower_bin_edge, upper_bin_edge)\n",
    "    if (upper_bin_edge - lower_bin_edge) % bin_width > 1e-5 and (upper_bin_edge - lower_bin_edge) % bin_width < bin_width - 1e-5:\n",
    "    #     print((upper_bin_edge - lower_bin_edge) % bin_width)\n",
    "        upper_bin_edge += (upper_bin_edge - lower_bin_edge) % bin_width\n",
    "#     print(lower_bin_edge, upper_bin_edge)\n",
    "\n",
    "    bin_edges = np.arange(lower_bin_edge, upper_bin_edge + bin_width, bin_width)\n",
    "    n_bins = len(bin_edges)-1\n",
    "    bin_means, bin_edges, bin_numbers = stats.binned_statistic(stellar_mass_log, ssfr_log, bins=bin_edges, statistic='mean')\n",
    "\n",
    "    bin_fqs = []\n",
    "    for bin_num in range(1, n_bins+1):\n",
    "        try:\n",
    "            fq = np.sum(ssfr_log[bin_numbers == bin_num] < log_ssfr_cutoff) / len(ssfr_log[bin_numbers == bin_num])\n",
    "        except:\n",
    "            if len(ssfr_log[bin_numbers == bin_num]) == 0:\n",
    "                print('bin number {:d} contains 0 points'.format(bin_num))\n",
    "                fq = 0\n",
    "            else:\n",
    "                print('some other error')\n",
    "        bin_fqs.append(fq)\n",
    "\n",
    "    bin_centers = [(bin_edges[i] + bin_edges[i+1])/2 for i in range(len(bin_edges)-1)]\n",
    "#     fig = plt.figure(i_red, figsize=(10,7))\n",
    "#     ax = plt.gca()\n",
    "#     plt.plot(bin_centers, bin_fqs)\n",
    "#     ax.set_ylim(bottom=0)\n",
    "#     ax.set_ylim(top=1)\n",
    "# #     ax.set_xlim(left=8)\n",
    "# #     ax.set_xlim(right=12)\n",
    "#     plt.title('Fraction of quenched galaxies at redshift {:.1f}'.format(redshift))\n",
    "# #     fig.savefig('fq_Z{:02.0f}.png'.format(redshift*10), bbox_inches = 'tight')\n",
    "#     plt.show()\n",
    "\n",
    "# print(bin_edges)\n",
    "# print(bin_centers)\n",
    "\n",
    "# plt.errorbar(bin_centers, bin_means, yerr=bin_stds, fmt = 'bo')\n",
    "\n",
    "    full_data_list = [[stell_mass, fq, error] for (stell_mass, fq) in zip(bin_centers, bin_fqs)]\n",
    "    full_data_list.insert(0, {'bin_widths': bin_width, 'bin_edges': bin_edges.tolist()})\n",
    "\n",
    "    with open(destination_directory + file_name + '.json', 'w+') as f:\n",
    "        json.dump(full_data_list, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock stellar mass halo mass relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_directory = '/home/magnus/data/galcats_nonzero_sfr_no_density_with_growth_rate_no_lastMajM/'\n",
    "destination_directory = '/home/magnus/data/mock_data/stellar_halo_mass_relations/'\n",
    "redshifts = [0, .1, .2, .5, 1, 2, 3, 4, 6, 8]\n",
    "\n",
    "np.seterr(invalid='raise')\n",
    "\n",
    "for i_red, redshift in enumerate(redshifts):\n",
    "\n",
    "    file_name = 'galaxies.Z{:02.0f}'.format(redshift*10)\n",
    "\n",
    "    bin_width = .2\n",
    "    error = .3\n",
    "\n",
    "    galfile = pd.read_hdf(original_directory + file_name + '.h5')\n",
    "    galaxies = galfile.values\n",
    "    gal_header = galfile.keys().tolist()\n",
    "\n",
    "    data_keys = {}\n",
    "    for col_nr, key in enumerate(gal_header):\n",
    "        data_keys[key] = col_nr\n",
    "\n",
    "    # Remove the smaller haloes\n",
    "    galaxies = galaxies[galaxies[:,data_keys['Halo_mass']] > 10.5, :]\n",
    "\n",
    "    halo_mass = galaxies[:, data_keys['Halo_mass']]\n",
    "    stellar_mass = galaxies[:, data_keys['Stellar_mass']]\n",
    "\n",
    "    min_halo_mass = np.amin(halo_mass)\n",
    "    max_halo_mass = np.amax(halo_mass)\n",
    "    \n",
    "    lower_bin_edge = np.floor(min_halo_mass * 1/bin_width)*bin_width\n",
    "    upper_bin_edge = np.ceil(max_halo_mass * 1/bin_width)*bin_width\n",
    "    print(min_halo_mass, max_halo_mass)\n",
    "    print(lower_bin_edge, upper_bin_edge)\n",
    "\n",
    "    if (upper_bin_edge - lower_bin_edge) % bin_width > 1e-5 and (upper_bin_edge - lower_bin_edge) % bin_width < bin_width - 1e-5:\n",
    "        print((upper_bin_edge - lower_bin_edge) % bin_width)\n",
    "        upper_bin_edge += (upper_bin_edge - lower_bin_edge) % bin_width\n",
    "#     print(lower_bin_edge, upper_bin_edge)\n",
    "\n",
    "    bin_edges = np.arange(lower_bin_edge, upper_bin_edge + bin_width, bin_width)\n",
    "    n_bins = len(bin_edges)-1\n",
    "    bin_means, bin_edges, bin_numbers = stats.binned_statistic(halo_mass, stellar_mass, bins=bin_edges, statistic='mean')\n",
    "\n",
    "    bin_centers = [(bin_edges[i] + bin_edges[i+1])/2 for i in range(len(bin_edges)-1)]\n",
    "    fig = plt.figure(i_red, figsize=(15,5))\n",
    "    ax = plt.subplot(121)\n",
    "    ax.errorbar(bin_centers, bin_means, yerr=error*np.ones(len(bin_centers)), fmt = 'bo')\n",
    "    ax = plt.subplot(122)\n",
    "    ax.plot(halo_mass[:10000], stellar_mass[:10000], 'b.', markersize=1)\n",
    "    plt.suptitle('Stellar masses at redshift {:.1f}'.format(redshift))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "    full_data_list = [[halo_mass, stellar_mass, error] for (halo_mass, stellar_mass) in zip(bin_centers, bin_means)]\n",
    "    full_data_list.insert(0, {'bin_widths': bin_width, 'bin_edges': bin_edges.tolist()})\n",
    "\n",
    "    with open(destination_directory + file_name + '.json', 'w+') as f:\n",
    "        json.dump(full_data_list, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  ['Universe_0']\n"
     ]
    }
   ],
   "source": [
    "filename = '/home/magnus/data/observational_data/all_data.h5'\n",
    "file = h5py.File(filename, 'r')\n",
    "#file?\n",
    "# List all groups\n",
    "print(\"Keys: \", list(file.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  ['CSFRD', 'Clustering', 'FQ', 'Model_Parameters', 'SMF', 'SSFR']\n"
     ]
    }
   ],
   "source": [
    "# Get the universe\n",
    "universe_0 = file['Universe_0']\n",
    "#universe_0?\n",
    "# List all objects in the universe\n",
    "print(\"Keys: \", list(universe_0.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys:  ['Data', 'Model', 'Sets']\n",
      "Keys of Data:  ['000 Li & White 2009 (z = 0.00 - 0.20)', '001 Baldry 2012 (z = 0.00 - 0.06)', '002 Bernardi 2013 (z = 0.00 - 0.20)', '003 Perez-Gonzalez 2008 (z = 0.00 - 0.20)', '004 Perez-Gonzalez 2008 (z = 0.20 - 0.40)', '005 Perez-Gonzalez 2008 (z = 0.40 - 0.60)', '006 Perez-Gonzalez 2008 (z = 0.60 - 0.80)', '007 Perez-Gonzalez 2008 (z = 0.80 - 1.00)', '008 Perez-Gonzalez 2008 (z = 1.00 - 1.30)', '009 Perez-Gonzalez 2008 (z = 1.30 - 1.60)', '010 Perez-Gonzalez 2008 (z = 1.60 - 2.00)', '011 Perez-Gonzalez 2008 (z = 2.00 - 2.50)', '012 Perez-Gonzalez 2008 (z = 2.50 - 3.00)', '013 Perez-Gonzalez 2008 (z = 3.00 - 3.50)', '014 Perez-Gonzalez 2008 (z = 3.50 - 4.00)', '015 Santini 2012 (z = 0.60 - 1.00)', '016 Santini 2012 (z = 1.00 - 1.40)', '017 Santini 2012 (z = 1.40 - 1.80)', '018 Santini 2012 (z = 1.80 - 2.50)', '019 Santini 2012 (z = 2.50 - 3.50)', '020 Santini 2012 (z = 3.50 - 4.50)', '021 Ilbert 2013 (z = 0.20 - 0.50)', '022 Ilbert 2013 (z = 0.50 - 0.80)', '023 Ilbert 2013 (z = 0.80 - 1.10)', '024 Ilbert 2013 (z = 1.10 - 1.50)', '025 Ilbert 2013 (z = 1.50 - 2.00)', '026 Ilbert 2013 (z = 2.00 - 2.50)', '027 Ilbert 2013 (z = 2.50 - 3.00)', '028 Ilbert 2013 (z = 3.00 - 4.00)', '029 Ilbert 2010 (z = 0.05 - 0.20)', '030 Ilbert 2010 (z = 0.20 - 0.40)', '031 Ilbert 2010 (z = 0.40 - 0.60)', '032 Ilbert 2010 (z = 0.60 - 0.80)', '033 Ilbert 2010 (z = 0.80 - 1.00)', '034 Ilbert 2010 (z = 1.00 - 1.20)', '035 Ilbert 2010 (z = 1.20 - 1.50)', '036 Ilbert 2010 (z = 1.50 - 2.00)', '037 Moustakas 2013 (z = 0.20 - 0.30)', '038 Moustakas 2013 (z = 0.30 - 0.40)', '039 Moustakas 2013 (z = 0.40 - 0.50)', '040 Moustakas 2013 (z = 0.50 - 0.65)', '041 Moustakas 2013 (z = 0.65 - 0.80)', '042 Moustakas 2013 (z = 0.80 - 1.00)', '043 Muzzin 2013 (z = 0.20 - 0.50)', '044 Muzzin 2013 (z = 0.50 - 1.00)', '045 Muzzin 2013 (z = 1.00 - 1.50)', '046 Muzzin 2013 (z = 1.50 - 2.00)', '047 Muzzin 2013 (z = 2.00 - 2.50)', '048 Muzzin 2013 (z = 2.50 - 3.00)', '049 Muzzin 2013 (z = 3.00 - 4.00)', '050 Caputi 2011 (z = 3.00 - 3.50)', '051 Caputi 2011 (z = 3.50 - 4.25)', '052 Caputi 2011 (z = 4.25 - 5.00)', '053 Pozzetti 2010 (z = 0.10 - 0.35)', '054 Pozzetti 2010 (z = 0.35 - 0.55)', '055 Pozzetti 2010 (z = 0.55 - 0.75)', '056 Pozzetti 2010 (z = 0.75 - 1.00)', '057 Marchesini 2009 (z = 1.30 - 2.00)', '058 Marchesini 2009 (z = 2.00 - 3.00)', '059 Marchesini 2009 (z = 3.00 - 4.00)', '060 Kajisawa 2009 (z = 0.50 - 1.00)', '061 Kajisawa 2009 (z = 1.00 - 1.50)', '062 Kajisawa 2009 (z = 1.50 - 2.50)', '063 Kajisawa 2009 (z = 2.50 - 3.50)', '064 Mortlock 2011 (z = 1.00 - 1.50)', '065 Mortlock 2011 (z = 1.50 - 2.00)', '066 Mortlock 2011 (z = 2.00 - 2.50)', '067 Mortlock 2011 (z = 2.50 - 3.00)', '068 Mortlock 2011 (z = 3.00 - 3.50)', '069 Lee 2012 (z = 3.50 - 4.00)', '070 Lee 2012 (z = 4.50 - 5.50)', '071 Gonzalez 2011 (z = 3.40 - 4.20)', '072 Gonzalez 2011 (z = 4.50 - 5.50)', '073 Gonzalez 2011 (z = 5.50 - 6.30)', '074 Gonzalez 2011 (z = 6.30 - 7.30)', '075 Duncan 2014 (z = 3.80 - 4.20)', '076 Duncan 2014 (z = 4.80 - 5.20)', '077 Duncan 2014 (z = 5.80 - 6.20)', '078 Duncan 2014 (z = 6.80 - 7.20)', '079 Song 2009 (z = 3.50 - 4.50)', '080 Song 2009 (z = 4.50 - 5.50)', '081 Song 2009 (z = 5.50 - 6.50)', '082 Song 2009 (z = 6.50 - 7.50)', '083 Song 2009 (z = 7.50 - 8.50)', '084 Grazian 2015 (z = 3.50 - 4.50)', '085 Grazian 2015  (z = 4.50 - 5.50)', '086 Grazian 2015 (z = 5.50 - 6.50)', '087 Grazian 2015 (z = 6.50 - 7.50)']\n"
     ]
    }
   ],
   "source": [
    "# Get the SMF objects from the universe\n",
    "smf = universe_0['SMF']\n",
    "#smf?\n",
    "# List all objects\n",
    "print(\"Keys: \", list(smf.keys()))\n",
    "# Get the dataset 'Data'\n",
    "data = smf['Data']\n",
    "print(\"Keys of Data: \", list(data.keys()))\n",
    "data_keys = list(data.keys())\n",
    "model = smf['Model']\n",
    "sets = smf['Sets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000 Li & White 2009 (z = 0.00 - 0.20)', '001 Baldry 2012 (z = 0.00 - 0.06)', '002 Bernardi 2013 (z = 0.00 - 0.20)', '003 Perez-Gonzalez 2008 (z = 0.00 - 0.20)', '004 Perez-Gonzalez 2008 (z = 0.20 - 0.40)', '005 Perez-Gonzalez 2008 (z = 0.40 - 0.60)', '006 Perez-Gonzalez 2008 (z = 0.60 - 0.80)', '007 Perez-Gonzalez 2008 (z = 0.80 - 1.00)', '008 Perez-Gonzalez 2008 (z = 1.00 - 1.30)', '009 Perez-Gonzalez 2008 (z = 1.30 - 1.60)', '010 Perez-Gonzalez 2008 (z = 1.60 - 2.00)', '011 Perez-Gonzalez 2008 (z = 2.00 - 2.50)', '012 Perez-Gonzalez 2008 (z = 2.50 - 3.00)', '013 Perez-Gonzalez 2008 (z = 3.00 - 3.50)', '014 Perez-Gonzalez 2008 (z = 3.50 - 4.00)', '015 Santini 2012 (z = 0.60 - 1.00)', '016 Santini 2012 (z = 1.00 - 1.40)', '017 Santini 2012 (z = 1.40 - 1.80)', '018 Santini 2012 (z = 1.80 - 2.50)', '019 Santini 2012 (z = 2.50 - 3.50)', '020 Santini 2012 (z = 3.50 - 4.50)', '021 Ilbert 2013 (z = 0.20 - 0.50)', '022 Ilbert 2013 (z = 0.50 - 0.80)', '023 Ilbert 2013 (z = 0.80 - 1.10)', '024 Ilbert 2013 (z = 1.10 - 1.50)', '025 Ilbert 2013 (z = 1.50 - 2.00)', '026 Ilbert 2013 (z = 2.00 - 2.50)', '027 Ilbert 2013 (z = 2.50 - 3.00)', '028 Ilbert 2013 (z = 3.00 - 4.00)', '029 Ilbert 2010 (z = 0.05 - 0.20)', '030 Ilbert 2010 (z = 0.20 - 0.40)', '031 Ilbert 2010 (z = 0.40 - 0.60)', '032 Ilbert 2010 (z = 0.60 - 0.80)', '033 Ilbert 2010 (z = 0.80 - 1.00)', '034 Ilbert 2010 (z = 1.00 - 1.20)', '035 Ilbert 2010 (z = 1.20 - 1.50)', '036 Ilbert 2010 (z = 1.50 - 2.00)', '037 Moustakas 2013 (z = 0.20 - 0.30)', '038 Moustakas 2013 (z = 0.30 - 0.40)', '039 Moustakas 2013 (z = 0.40 - 0.50)', '040 Moustakas 2013 (z = 0.50 - 0.65)', '041 Moustakas 2013 (z = 0.65 - 0.80)', '042 Moustakas 2013 (z = 0.80 - 1.00)', '043 Muzzin 2013 (z = 0.20 - 0.50)', '044 Muzzin 2013 (z = 0.50 - 1.00)', '045 Muzzin 2013 (z = 1.00 - 1.50)', '046 Muzzin 2013 (z = 1.50 - 2.00)', '047 Muzzin 2013 (z = 2.00 - 2.50)', '048 Muzzin 2013 (z = 2.50 - 3.00)', '049 Muzzin 2013 (z = 3.00 - 4.00)', '050 Caputi 2011 (z = 3.00 - 3.50)', '051 Caputi 2011 (z = 3.50 - 4.25)', '052 Caputi 2011 (z = 4.25 - 5.00)', '053 Pozzetti 2010 (z = 0.10 - 0.35)', '054 Pozzetti 2010 (z = 0.35 - 0.55)', '055 Pozzetti 2010 (z = 0.55 - 0.75)', '056 Pozzetti 2010 (z = 0.75 - 1.00)', '057 Marchesini 2009 (z = 1.30 - 2.00)', '058 Marchesini 2009 (z = 2.00 - 3.00)', '059 Marchesini 2009 (z = 3.00 - 4.00)', '060 Kajisawa 2009 (z = 0.50 - 1.00)', '061 Kajisawa 2009 (z = 1.00 - 1.50)', '062 Kajisawa 2009 (z = 1.50 - 2.50)', '063 Kajisawa 2009 (z = 2.50 - 3.50)', '064 Mortlock 2011 (z = 1.00 - 1.50)', '065 Mortlock 2011 (z = 1.50 - 2.00)', '066 Mortlock 2011 (z = 2.00 - 2.50)', '067 Mortlock 2011 (z = 2.50 - 3.00)', '068 Mortlock 2011 (z = 3.00 - 3.50)', '069 Lee 2012 (z = 3.50 - 4.00)', '070 Lee 2012 (z = 4.50 - 5.50)', '071 Gonzalez 2011 (z = 3.40 - 4.20)', '072 Gonzalez 2011 (z = 4.50 - 5.50)', '073 Gonzalez 2011 (z = 5.50 - 6.30)', '074 Gonzalez 2011 (z = 6.30 - 7.30)', '075 Duncan 2014 (z = 3.80 - 4.20)', '076 Duncan 2014 (z = 4.80 - 5.20)', '077 Duncan 2014 (z = 5.80 - 6.20)', '078 Duncan 2014 (z = 6.80 - 7.20)', '079 Song 2009 (z = 3.50 - 4.50)', '080 Song 2009 (z = 4.50 - 5.50)', '081 Song 2009 (z = 5.50 - 6.50)', '082 Song 2009 (z = 6.50 - 7.50)', '083 Song 2009 (z = 7.50 - 8.50)', '084 Grazian 2015 (z = 3.50 - 4.50)', '085 Grazian 2015  (z = 4.50 - 5.50)', '086 Grazian 2015 (z = 5.50 - 6.50)', '087 Grazian 2015 (z = 6.50 - 7.50)']\n"
     ]
    }
   ],
   "source": [
    "print(list(data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0, bin_width: 0.1000\n",
      "i: 1, bin_width: 0.2000\n",
      "i: 2, bin_width: 0.1000\n",
      "i: 3, bin_width: 0.2000\n",
      "i: 4, bin_width: 0.2000\n",
      "i: 5, bin_width: 0.2000\n",
      "i: 6, bin_width: 0.2000\n",
      "i: 7, bin_width: 0.2000\n",
      "i: 8, bin_width: 0.2000\n",
      "i: 9, bin_width: 0.2000\n",
      "i: 10, bin_width: 0.2000\n",
      "i: 11, bin_width: 0.2000\n",
      "i: 12, bin_width: 0.2000\n",
      "i: 13, bin_width: 0.2000\n",
      "i: 14, bin_width: 0.2000\n",
      "i: 15, bin_width: 0.2000\n",
      "i: 16, bin_width: 0.2000\n",
      "i: 17, bin_width: 0.2000\n",
      "i: 18, bin_width: 0.2000\n",
      "i: 19, bin_width: 0.2000\n",
      "i: 20, bin_width: 0.2000\n",
      "i: 21, bin_width: 0.2850\n",
      "i: 22, bin_width: 0.2500\n",
      "i: 23, bin_width: 0.2500\n",
      "i: 24, bin_width: 0.2500\n",
      "i: 25, bin_width: 0.2500\n",
      "i: 26, bin_width: 0.2000\n",
      "i: 27, bin_width: 0.1600\n",
      "i: 28, bin_width: 0.1600\n",
      "i: 29, bin_width: 0.4300\n",
      "i: 30, bin_width: 0.3000\n",
      "i: 31, bin_width: 0.2850\n",
      "i: 32, bin_width: 0.2400\n",
      "i: 33, bin_width: 0.2200\n",
      "i: 34, bin_width: 0.1800\n",
      "i: 35, bin_width: 0.1500\n",
      "i: 36, bin_width: 0.0600\n",
      "i: 37, bin_width: 0.1000\n",
      "i: 38, bin_width: 0.1000\n",
      "i: 39, bin_width: 0.1000\n",
      "i: 40, bin_width: 0.1000\n",
      "i: 41, bin_width: 0.1000\n",
      "i: 42, bin_width: 0.1000\n",
      "i: 43, bin_width: 0.1000\n",
      "i: 44, bin_width: 0.1000\n",
      "i: 45, bin_width: 0.1000\n",
      "i: 46, bin_width: 0.1000\n",
      "i: 47, bin_width: 0.1000\n",
      "i: 48, bin_width: 0.2000\n",
      "i: 49, bin_width: 0.2000\n",
      "i: 50, bin_width: 0.2000\n",
      "i: 51, bin_width: 0.2000\n",
      "i: 52, bin_width: 0.2000\n",
      "i: 53, bin_width: 0.2900\n",
      "i: 54, bin_width: 0.2800\n",
      "i: 55, bin_width: 0.2900\n",
      "i: 56, bin_width: 0.2900\n",
      "i: 57, bin_width: 0.3000\n",
      "i: 58, bin_width: 0.2900\n",
      "i: 59, bin_width: 0.2900\n",
      "i: 60, bin_width: 0.2500\n",
      "i: 61, bin_width: 0.2500\n",
      "i: 62, bin_width: 0.2500\n",
      "i: 63, bin_width: 0.2500\n",
      "i: 64, bin_width: 0.2500\n",
      "i: 65, bin_width: 0.2500\n",
      "i: 66, bin_width: 0.2500\n",
      "i: 67, bin_width: 0.2500\n",
      "i: 68, bin_width: 0.2500\n",
      "i: 69, bin_width: 0.2500\n",
      "i: 70, bin_width: 0.2500\n",
      "i: 71, bin_width: 0.5000\n",
      "i: 72, bin_width: 0.5000\n",
      "i: 73, bin_width: 0.5000\n",
      "i: 74, bin_width: 0.5000\n",
      "i: 75, bin_width: 0.2500\n",
      "i: 76, bin_width: 0.3100\n",
      "i: 77, bin_width: 0.3500\n",
      "i: 78, bin_width: 0.3600\n",
      "i: 79, bin_width: 0.5000\n",
      "i: 80, bin_width: 0.5000\n",
      "i: 81, bin_width: 0.5000\n",
      "i: 82, bin_width: 0.5000\n",
      "i: 83, bin_width: 0.5000\n",
      "i: 84, bin_width: 0.2000\n",
      "i: 85, bin_width: 0.2000\n",
      "i: 86, bin_width: 0.2000\n",
      "i: 87, bin_width: 0.2000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(data.keys()))):\n",
    "    first_data_key = data[list(data.keys())[i]]\n",
    "    bin_width = first_data_key.value[1][0] - first_data_key.value[0][0]\n",
    "    print('i: {:d}, bin_width: {:.4f}'.format(i, bin_width))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(39, 0, 0., 0.2, b'Li & White 2009'), (21, 39, 0., 0.06, b'Baldry 2012'), (32, 60, 0., 0.2, b'Bernardi 2013'), (20, 92, 0., 0.2, b'Perez-Gonzalez 2008'), (20, 112, 0.2, 0.4, b'Perez-Gonzalez 2008'), (17, 132, 0.4, 0.6, b'Perez-Gonzalez 2008'), (14, 149, 0.6, 0.8, b'Perez-Gonzalez 2008'), (13, 163, 0.8, 1., b'Perez-Gonzalez 2008'), (13, 176, 1., 1.3, b'Perez-Gonzalez 2008'), (11, 189, 1.3, 1.6, b'Perez-Gonzalez 2008'), (10, 200, 1.6, 2., b'Perez-Gonzalez 2008'), (9, 210, 2., 2.5, b'Perez-Gonzalez 2008'), (7, 219, 2.5, 3., b'Perez-Gonzalez 2008'), (6, 226, 3., 3.5, b'Perez-Gonzalez 2008'), (6, 232, 3.5, 4., b'Perez-Gonzalez 2008'), (19, 238, 0.6, 1., b'Santini 2012'), (15, 257, 1., 1.4, b'Santini 2012'), (13, 272, 1.4, 1.8, b'Santini 2012'), (11, 285, 1.8, 2.5, b'Santini 2012'), (9, 296, 2.5, 3.5, b'Santini 2012'), (8, 305, 3.5, 4.5, b'Santini 2012'), (15, 313, 0.2, 0.5, b'Ilbert 2013'), (13, 328, 0.5, 0.8, b'Ilbert 2013'), (12, 341, 0.8, 1.1, b'Ilbert 2013'), (10, 353, 1.1, 1.5, b'Ilbert 2013'), (10, 363, 1.5, 2., b'Ilbert 2013'), (12, 373, 2., 2.5, b'Ilbert 2013'), (11, 385, 2.5, 3., b'Ilbert 2013'), (11, 396, 3., 4., b'Ilbert 2013'), (10, 407, 0.05, 0.2, b'Ilbert 2010'), (10, 417, 0.2, 0.4, b'Ilbert 2010'), (10, 427, 0.4, 0.6, b'Ilbert 2010'), (10, 437, 0.6, 0.8, b'Ilbert 2010'), (10, 447, 0.8, 1., b'Ilbert 2010'), (10, 457, 1., 1.2, b'Ilbert 2010'), (8, 467, 1.2, 1.5, b'Ilbert 2010'), (10, 475, 1.5, 2., b'Ilbert 2010'), (26, 485, 0.2, 0.3, b'Moustakas 2013'), (24, 511, 0.3, 0.4, b'Moustakas 2013'), (23, 535, 0.4, 0.5, b'Moustakas 2013'), (18, 558, 0.5, 0.65, b'Moustakas 2013'), (17, 576, 0.65, 0.8, b'Moustakas 2013'), (11, 593, 0.8, 1., b'Moustakas 2013'), (37, 604, 0.2, 0.5, b'Muzzin 2013'), (29, 641, 0.5, 1., b'Muzzin 2013'), (24, 670, 1., 1.5, b'Muzzin 2013'), (16, 694, 1.5, 2., b'Muzzin 2013'), (13, 710, 2., 2.5, b'Muzzin 2013'), (6, 723, 2.5, 3., b'Muzzin 2013'), (6, 729, 3., 4., b'Muzzin 2013'), (7, 735, 3., 3.5, b'Caputi 2011'), (7, 742, 3.5, 4.25, b'Caputi 2011'), (6, 749, 4.25, 5., b'Caputi 2011'), (11, 755, 0.1, 0.35, b'Pozzetti 2010'), (7, 766, 0.35, 0.55, b'Pozzetti 2010'), (5, 773, 0.55, 0.75, b'Pozzetti 2010'), (3, 778, 0.75, 1., b'Pozzetti 2010'), (8, 781, 1.3, 2., b'Marchesini 2009'), (7, 789, 2., 3., b'Marchesini 2009'), (6, 796, 3., 4., b'Marchesini 2009'), (14, 802, 0.5, 1., b'Kajisawa 2009'), (10, 816, 1., 1.5, b'Kajisawa 2009'), (10, 826, 1.5, 2.5, b'Kajisawa 2009'), (6, 836, 2.5, 3.5, b'Kajisawa 2009'), (14, 842, 1., 1.5, b'Mortlock 2011'), (12, 856, 1.5, 2., b'Mortlock 2011'), (11, 868, 2., 2.5, b'Mortlock 2011'), (10, 879, 2.5, 3., b'Mortlock 2011'), (11, 889, 3., 3.5, b'Mortlock 2011'), (10, 900, 3.5, 4., b'Lee 2012'), (9, 910, 4.5, 5.5, b'Lee 2012'), (7, 919, 3.4, 4.2, b'Gonzalez 2011'), (7, 926, 4.5, 5.5, b'Gonzalez 2011'), (7, 933, 5.5, 6.3, b'Gonzalez 2011'), (6, 940, 6.3, 7.3, b'Gonzalez 2011'), (10, 946, 3.8, 4.2, b'Duncan 2014'), (9, 956, 4.8, 5.2, b'Duncan 2014'), (7, 965, 5.8, 6.2, b'Duncan 2014'), (4, 972, 6.8, 7.2, b'Duncan 2014'), (9, 976, 3.5, 4.5, b'Song 2009'), (9, 985, 4.5, 5.5, b'Song 2009'), (7, 994, 5.5, 6.5, b'Song 2009'), (8, 1001, 6.5, 7.5, b'Song 2009'), (6, 1009, 7.5, 8.5, b'Song 2009'), (14, 1015, 3.5, 4.5, b'Grazian 2015'), (13, 1029, 4.5, 5.5, b'Grazian 2015 '), (8, 1042, 5.5, 6.5, b'Grazian 2015'), (6, 1050, 6.5, 7.5, b'Grazian 2015')]\n"
     ]
    }
   ],
   "source": [
    "print(list(sets))\n",
    "#sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model))\n",
    "#model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(list(data['000 Li & White 2009 (z = 0.00 - 0.20)']))\n",
    "print(list(data))\n",
    "#data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 + 1/(1+.2))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obj_0 = data[data_keys[0]]\n",
    "print(list(data_obj_0))\n",
    "#data_obj_0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot create a storer if the object is not existing nor a value are passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-13786dd61e1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/magnus/data/observational_data/all_data.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Universe_0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfile_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m                                      'contains multiple datasets.')\n\u001b[1;32m    393\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcandidate_only_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v_pathname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_close\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_close\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;31m# if there is an error, close the store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, key, where, start, stop, columns, iterator, chunksize, auto_close, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;31m# create the storer and axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mwhere\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_term\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_storer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.6/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36m_create_storer\u001b[0;34m(self, group, format, value, append, **kwargs)\u001b[0m\n\u001b[1;32m   1254\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                     raise TypeError(\n\u001b[0;32m-> 1256\u001b[0;31m                         \u001b[0;34m\"cannot create a storer if the object is not existing \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m                         \"nor a value are passed\")\n\u001b[1;32m   1258\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot create a storer if the object is not existing nor a value are passed"
     ]
    }
   ],
   "source": [
    "file_name = '/home/magnus/data/observational_data/all_data.h5'\n",
    "\n",
    "file = pd.read_hdf(file_name, key='Universe_0')\n",
    "file_header = file.keys().tolist()\n",
    "print(file_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redshift 7.50 - 8.50. Survey b'Song 2009'\n"
     ]
    }
   ],
   "source": [
    "predicted_redshift = 8\n",
    "data_to_load = 'smf'\n",
    "\n",
    "data_dir = '/home/magnus/data/observational_data/all_data.h5'\n",
    "file = h5py.File(data_dir, 'r')\n",
    "universe_0 = file['Universe_0']\n",
    "\n",
    "if data_to_load == 'smf':\n",
    "    smf = universe_0['SMF']\n",
    "    data = smf['Data']\n",
    "    sets = smf['Sets']\n",
    "\n",
    "    for i_set, dataset in enumerate(list(sets)):\n",
    "        \n",
    "        if predicted_redshift >= dataset[2] and predicted_redshift <= dataset[3]:\n",
    "            print('Redshift {:.2f} - {:.2f}. Survey {}'.format(dataset[2], dataset[3], dataset[-1]))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
